{"/":{"title":"The Dyslexic Bioinformatician","content":"\n## About me\nI'm Damon, a year 4 BSc Data Science (Bioinformatics) apprentice working in the ToLa (Tree of Life Assembly team) at the Wellcome Genome Campus in Hinxton.\n\nThis blog will be used as evidence of learning in a final year portfolio.\n\n## Contents\n\n| Link | Description | \n|-----|-----|\n| [[Computer Science/University and CS Homepage]] | My university blog-style notes |\n| [[Work-based Projects/Work-based Project Homepage]] | Notes on work-based projects |\n| [[Personal Projects/Personal Project Homepage]] | Notes on my personal \"for fun\" projects | \n| [[Languages and Technologies/Languages and Technologies Homepage]] | Notes on the different technologies and languages I've learned |\n\n## Other Stuff and Interests\n\n| Link | Description | \n|-----|-----|\n| Books | Interesting Books |\n\n#### How is this hosted?\nThis blog is written with Obsidian and hosted on GitHub Pages via [Quartz](https://github.com/jackyzha0/quartz)","lastmodified":"2022-12-16T13:05:37.543835841Z","tags":null},"/Computer-Science/University-and-CS-Homepage":{"title":"","content":"### Portfolio Pieces\nAs a note, any GitHub commits reported as either dp24 or DLBPointon are my work. dp24 is a work based account and DLBPointon is my usual account.\n\nThese peices are for use in the Anglia Ruskin University BSc Data Science (Bioinformatics) End Point Assessment.\n\nTable generated via the Templater and Dataview template: [[templates/portfolio_projects]].\n\n| File                                                                             | Date          | Description                                                                          | Type                                                                                         | KSBs         |\n| -------------------------------------------------------------------------------- | ------------- | ------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------- | ------------ |\n| [[Portfolio Pieces/Data driven decision making.md\\|Data driven decision making]] | 50@16-12-2022 | How data has effected how a project has gone forward.                                | \u003cul\u003e\u003cli\u003eLearning\u003c/li\u003e\u003c/ul\u003e                                                                   | \\-           |\n| [[Portfolio Pieces/Forefront of Datascience.md\\|Forefront of Datascience]]       | 50@16-12-2022 | How I have continued learning and pushing towards new technologies.                  | \u003cul\u003e\u003cli\u003eLearning\u003c/li\u003e\u003c/ul\u003e                                                                   | B1           |\n| [[Work-based Projects/gEVAL Data Cleaner.md\\|gEVAL Data Cleaner]]                | 50@16-12-2022 | A python script to download and parse ensembl and ncbi genomic data.                 | \u003cul\u003e\u003cli\u003ePython Script\u003c/li\u003e\u003c/ul\u003e                                                              | \\-           |\n| [[Portfolio Pieces/GRIT-realtime.md\\|GRIT-realtime]]                             | 50@16-12-2022 | A Full-stack project to generate graphical summaries of post-curation data           | \u003cul\u003e\u003cli\u003eFull-stack Project\u003c/li\u003e\u003cli\u003eDatabase-PostreSQL\u003c/li\u003e\u003cli\u003eSoftware Development\u003c/li\u003e\u003c/ul\u003e | K5-3, S6, B1 |\n| [[Portfolio Pieces/Real-world patterns in data.md\\|Real-world patterns in data]] | 50@16-12-2022 | Patterns found in real-world data                                                    | \u003cul\u003e\u003cli\u003eLearning\u003c/li\u003e\u003c/ul\u003e                                                                   | K3-3         |\n| [[Portfolio Pieces/TeloSearch.md\\|TeloSearch]]                                   | 50@16-12-2022 | A pipeline to find putative telomeric sequence in good quality scaffolded assemblies | \u003cul\u003e\u003cli\u003ePipeline\u003c/li\u003e\u003cli\u003eSoftware Development\u003c/li\u003e\u003c/ul\u003e                                      | \\-           |\n| [[Work-based Projects/TreeVal.md\\|TreeVal]]                                      | 50@16-12-2022 | A gEVAL replacement, written in NextFlow and Python3                                 | \u003cul\u003e\u003cli\u003ePipeline\u003c/li\u003e\u003cli\u003eSoftware Development\u003c/li\u003e\u003c/ul\u003e                                      | \\-           |\n\n\n\n\n","lastmodified":"2022-12-16T13:05:37.539835742Z","tags":null},"/Languages-and-Technologies/Languages-and-Technologies-Homepage":{"title":"","content":"\n\n| Language | Description |\n|--|--|\n| Python 3 | My first language, generalist\n| JavaScript | Used in multiple projects, web focused\n| Bash | Language of the command line |\n| Nextflow | Written in Groovy, Data science pipelining language |\n","lastmodified":"2022-12-16T13:05:37.539835742Z","tags":null},"/Personal-Projects/NCBI-Taxonomy-QuickAdd":{"title":"","content":"Built whilst I was getting to documenting the organsisms I was working on in DTOL this little project allowed me to get to: know the Obsidian environment a bit better, improve my skills in JavaScript and create a local database on the bugs I like (bees and wasps).\n\n#### GitHub\n[Here](https://github.com/DLBPointon/QuickAdd-ncbi)\n\n#### Tech Stack\n| Technology | Docs | Implimented | Description | \n|--|--|--|--|\n| JavaScript | | Done | Language |\n| Markdown | | Done | Language |\n| Obsidian | | Done | Knowledge management software |\n\n#### Output\n```\n# Tiphia femorata\n\n## Taxonomic Data\n### TaxID:: 330862\n### RankOfQuery:: species\n### Lineage:: [[Eukaryota]], [[Metazoa]], [[Ecdysozoa]], [[Arthropoda]],\n                [[Hexapoda]], [[Insecta]], [[Pterygota]], [[Neoptera]],\n                [[Endopterygota]], [[Hymenoptera]], [[Apocrita]], [[Aculeata]],\n                [[Tiphioidea]], [[Tiphiidae]], [[Tiphiinae]], [[Tiphia]], [[]]\n\n## Genetic Code\n### GeneticCode:: 1\n### MitoGeneticCode:: 5\n```\n\nThis allows for each segment of the lineage to create a linked mention to another note and using a Plugin called DataView you would be able to collate all Aprocrita, for example, you are working on.\n\n#### Future work\n\n[[NCBI-Notes]]\nCurrently the scope of this pseudo plugin is limited to the taxonomic data that ncbi has on an organism, this is just a fraction of the whole API. I would like to create a stand alone Plugin that can query the API and generate a note with data denoted in a template.\n\nI'm aware that the user base for such a Plugin will be limited to the handful of bioinformaticians that use Obsidian but it gives the chance to understand the Obsidian API, JavaScript and NCBI API.","lastmodified":"2022-12-16T13:05:37.539835742Z","tags":null},"/Personal-Projects/Personal-Project-Homepage":{"title":"","content":"A page for the projects i'm working on or planning to work on.\n\n## In Active Development\n\n| Project | Description | Type | Stage |\n|---|---|---|---|\n| [[Personal Projects/Vault]] | My Raspberry Pi4 4gb OMV6 based NAS and media server. | Hardware | Completed |\n| [[Personal Projects/PiStack]] | A 4 node, Kubernetes cluster for training. | Hardware | Completed (not in use) |\n| [[Personal Projects/TMDB]] | A Traumatic Media DataBase, needs renaming | Software |Development and Further Planning |\n| [[Personal Projects/NCBI Taxonomy QuickAdd]] | A QuickAdd for Obsidian to add NCBI taxonomic data as a note | Software |Completed |\n\n\n## Projects in waiting\n\n| Project | Description | Type | Stage |\n|---|---|---|---|\n| System Plot | An Obsidian Plugin, a different way of visualising folder-file relationships | Software | Waiting on Time |\n| NCBI-Notes | An Obsidian Plugin, a stand alone plugin that enables searching on the NCBI API in Obsidian | Software | Waiting on Time |\n| CyberDeck | I've fallen in love with the idea of a Raspberry Pi Cyber Deck and would love to get involved in the community | Hardware / Software | Waiting on Time and Money |\n\n\n","lastmodified":"2022-12-16T13:05:37.539835742Z","tags":null},"/Personal-Projects/PiStack":{"title":"","content":"","lastmodified":"2022-12-16T13:05:37.539835742Z","tags":null},"/Personal-Projects/TMDB":{"title":"","content":"The Traumatic Media DataBase is a project I started in 2021 in order to provide a simple way to search for media which may have a scenes that could be considered traumatic. \n\nThis was inspired through seeing the effects of Birth Trauma on multiple woman I personally know and, through my wife, the effect that the trope of suprise traumatic birth scenes in popular media \ncan have.\n\nMy plan for this project is to make a robust full stack project and then \"give\" it to the Birth Trauma Association to aid in raising awareness. This project has also been built with other traumatic events in mind and can be expanding on when needed.\n\n#### GitHub (Currently Private)\n[TMDB Project Page](https://github.com/DLBPointon/tmdb_project)\n\n#### Tech Stack\n| Technology | Docs | Implimented | Description | \n|--|--|--|--|\n| Angular |  |  | Single Page Application |\n| PostgreSQL |  |  | The backend database |\n| PostgREST |  |  | A database - API layer |\n\n## Issues\n\n### Issue 1 - Schema\nMain issue stopping further work is the database schema, there is an issue between the table main_2_traum_ref (which assigns the media to multiple trauma events) and the traumatic_table (which details the type of trauma (which is in no particular order)).\n\n```\ndb_1   | 2021-09-30 07:31:22.803 UTC [91] ERROR:  insert or update on table \"main_2_traum_ref\" violates foreign key constraint \"traumatic\"\ndb_1   | 2021-09-30 07:31:22.803 UTC [91] DETAIL:  Key (traum_pk)=(1) is not present in table \"traumatic_table\".\ndb_1   | 2021-09-30 07:31:22.803 UTC [91] STATEMENT:  COPY main_2_traum_ref FROM '/var/lib/postgresql/tmdb/main_2_traum_ref.tsv' CSV HEADER DELIMITER E'\\t' NULL '';\ndb_1   | psql:/docker-entrypoint-initdb.d/20_db_fill.sql:5: ERROR:  insert or update on table \"main_2_traum_ref\" violates foreign key constraint \"traumatic\"\ndb_1   | DETAIL:  Key (traum_pk)=(1) is not present in table \"traumatic_table\".\n```\n\nOnly enough, talking with multiple other people that have worked on databases, the actual code is correct, but something seems to be getting in the way.\n\n#### Fix\nI think the database just needs redesigning, it isn't as optimal as it could be.\n\n### Issue 2 - Hosting\n\nI could self-host the application on [[PiStack]], but will there be an issue with scaling as I will be taking this to the Birth Trauma Association, are 4 Pi's enough? \n\nSecurity, how would I secure a self-hosted app like this? Is the domain provider able to secure this?\n\n#### Fix\nMuch more reading, talk to some people who know much more in this topic.\n\n### Issue 3 - Adding new events\n\nI can't sit at a computer verifying new additions, but I also can't have a completely open DB. Security would be a nightmare as, lets face it people would attack it. \n\nDo I implement a login feature knowing that it would put some people off logging media?\n\nThis would require JWS tokens and I just don't know enough in the field.\n\n### Fix \nMuch more reading, talk to some people who know much more in this topic.\n\n### Issue 4 - Scoring\nWe cannot score based on the trauma, it creates a heirarchy of \"this trauma is more traumatic than that one\". Trauma is trauma and cannot be scored. So I propose a method based on the number of \"events\" / length of time to consume the media or maybe number of \"events\" per hour/page. This could be calculated in the DB or on the fly with some JavaScript.\n\nA score based on the number of triggers, length of film/book/show as an indicator of whether you should watch it Maybe something like in grt-realtime, javascript traffic light for if trigger score above x then give traffic light colour.","lastmodified":"2022-12-16T13:05:37.539835742Z","tags":null},"/Personal-Projects/Vault":{"title":"","content":"An Raspberry Pi4 4gb based NAS using OMV6 and Docker, that I also call ShortCrust.\n\n## Hardware\n| Hardware | Description |\n|---|---|\n|Raspberry Pi 4 | 4Gb + 32Gb SD card |\n| External HDD | 4Tb |\n| External HDD | 10 Tb |\n\n## Software\n| Service | Port | Description | Site |\n|---|---|---| --- |\n| Open Media Vault 6 | 10.0.0.2 | The NAS operating system | [OMV](https://www.openmediavault.org/)\n| Homepage | :3100 | A Homepage to collect all services | [Homepage GH](https://github.com/benphelps/homepage)\n| Portainer | :9000 | Docker manager | [Portainer](https://www.portainer.io/)\n| Plex | :32400 | Media viewer | [Plex Docker](https://github.com/linuxserver/docker-plex)\n| Tautulli | :8181 | Plex Stat Tracker | [Tautulli Docker](https://hub.docker.com/r/tautulli/tautulli)\n| Airsonic |  :4040 | Local Music Player | [Airsonic](https://hub.docker.com/r/linuxserver/airsonic)\n| Kavita | :5000 | Comic and Book Viewer | [Kavita Wiki](https://wiki.kavitareader.com/en)\n| meTube | :9090 | Video Download Server | [MeTube GH](https://github.com/alexta69/metube)\n| Ubuntu | :1234 | Dev environment | [Ubuntu Docker](https://hub.docker.com/_/ubuntu)\n\n\n\n","lastmodified":"2022-12-16T13:05:37.539835742Z","tags":null},"/Portfolio-Pieces/Data-driven-decision-making":{"title":"Data driven decision making","content":"\nContribution: Nextflow DSL2, Python 3.9, bash\n\nWorking with: ToL\n\nTopic: Collaborative Projects, Decision making, Data science\n\nKSB: K3-3\n\n---\n\nDescription:: How data has effected how a project has gone forward.\n\nThrough my work in DTOL, data driven decision making has been ubiquitous. Through Tree Of Life Research and Development (ToL RnD) meetings we see the effects of data driven decision making on:\n\n- The Core Labs team and their experiments in attemping to improve sequencing pipelines, and the effect on sequencing yield due to the complex genomes of polyploid plants and highly repetitive genomes.\n\n- The Faculty Research groups in where they must decide on the best ways in which to massage their data to produce informative results. The Merian Unit Analysis (not yet published), which is being added to the [[TreeVal]] Project, needed iterative refinement to best identify putative ancestral units. This will go on to be used in [[TreeVal]] to better improve both curation and Lepidopteran genetics.\n\n- GRIT require the use of a multitude of data in order to correctly identify scaffolds which may require breaking, joining or even removing depending on a variety of features such as: coverage changes, telomeric sequence, and strength of HiC signal. All of these impact the quality of the final genomic assembly.\n\t-  iyTipFemo1 HiC map changes\n\n\tThis data is also entered into Jira, for ingestion into other data-driven projects, such as [[GRIT-realtime]]. This takes the curation data and collates it into a form usable for management decisions and publications.\n\n- ToLa has been testing the use of Ultra-Low Input sequencing methods and comparing these against the current suite of sequencing methods already in use at Sanger. This is acheived by taking the raw reads from both methods, assembling the filtered reads and then collecting stats on those final assemblies.\n\t- Image of assembly graphs from ksenia?\n\n- [[TreeVal]] has required data driven decision making too, the documentation for some methods and functions---performed by the gEVAL/ensembl database---have been lost and so could not be replicated in JBrowse (the front-end component of TreeVal). The selfcomp (Self complementary sequence) track is a prime example, Minimap2 resullts in blocks of hits which has required iterative refinements to mimic the results shown on gEVAL.\n\t- Images of gEVALs output as well as JBrowse pre and post selfcomp fix.\n\nThis project has also involved close co-operation with GRIT in order to ensure that the curators could reach the same conclusions given the gEVAL build or the TreeVal build. ","lastmodified":"2022-12-16T13:05:37.539835742Z","tags":null},"/Portfolio-Pieces/Ethics-and-Compliance":{"title":"","content":"In the world of science ethics there is one protocol which stands above all else, the Ngoya Protocol. This protocol covers....\n\n\nAlthough the Ngoya Protocol is undoubtably beneficial, it does indeed damage the speed at which data science projects can proceed.","lastmodified":"2022-12-16T13:05:37.539835742Z","tags":null},"/Portfolio-Pieces/Forefront-of-Datascience":{"title":"Forefront of Datascience","content":"\nContribution:: Nextflow DSL2, Python 3.9, bash\n\nWorking with:: ToL\n\nTopic:: Curiosity, Data science\n\nKSBs:: B1\n\n---\n\nDescription:: How I have continued learning and pushing towards new technologies.\n\nOver the past three years as I have become comfortable with Sanger systems I have started to try and push my knowldedge further. I have done this by working on by:\n\n- [[TMDB]] - Updating personal projects into vue.js from HTML and JavaScript. \n\n- [[TreeVal]] - Bring amoungst the first teams at Sanger to move towards a Nextflow + NF-core standards + ToLIT standards.\n\n- [[TreeVal]] - Developing a new pipeline and frontend combination based on newer technology to replace the current solution as well as ship to other collaborative groups.\n\n- Slack Bots - Although sounding simple, these bots interact with both the Slack API as well as the JIRA API in order to pull data meeting certain specifications.","lastmodified":"2022-12-16T13:05:37.539835742Z","tags":null},"/Portfolio-Pieces/GRIT-realtime":{"title":"GRIT-realtime","content":"\nGitHub:: [https://github.com/DLBPointon/grt-v5](https://github.com/DLBPointon/grt-v5)\n\nContribution:: JavaScript, HTML, Python 3.9, bash, Project Management, APIs, Database\n\nWorking with:: Solo project reporting to manager\n\nTopic:: Designing new systems to meet organisational goals.\n\nKSBs:: K5-3, S6, B1\n\n---\n\nDescription:: A Full-stack project to generate graphical summaries of post-curation data\n\n### The Project\nGRIT-realtime—grt, [https://grit-realtime.tol.sanger.ac.uk/](https://grit-realtime.tol.sanger.ac.uk/)—was originally developed as coursework for the Bioinformatics in the Workplace module. Prior to this project, statistics and graphs would be gathered by: downloading a csv of data, importing this into Microsoft Excel and then manually curating the data (line by line), and, then generating the statistics and graphs required for reports and papers. This resulted in a significant time sink for management and so a more modern and automated solution was required.\n\nThe project, see figure 1, uses Python 3.9 with the jira_python module to interact with the Jira Database and pull data that meets built in requirements, e.g., belongs to a GRIT project and has made it the post-curation step of the workflow.\n\nThe data is then parsed to pull the correct information from free text fields, and calculate statistics such as manual interventions per 1Gb of genome. The output tsv file, is then ingested by a PostgreSQL database which can then serve a frontend via a PostgREST API layer. The graph views can then be altered via a series of drop-down menus to tailor the view, see figure 2.\n\n![grt-v5 schematic](https://lh3.googleusercontent.com/HxWonAXDQfPcStDizOTl3BGOmcTN4hF-wwym_LW41MqfxQ31G6GywzSadzPcbuw3YesN8NUJM6neE60HTDnxxQAjbUaRPchhw-8njxkLq-W_5wFLej_X-qSUUDTntle09mH8T2XR8tJiLUSQ96m28a64tiM_SUk-KdP6yqB_v7KZ648Z4Fd3kfDc2FvIzw)\nFigure 1: An overview of the GRIT-realtime architechture. Blue is a script, Green a source of data and orange colours the webserving components.\n\n**![](https://lh4.googleusercontent.com/svXpOUgTFa12HqLgOPlmGRRTuZNFjhTJ46R6HdEP4OTkRJGZODrcYZgQ9D1uoR3mDjWX6uiIt4Uj45lnfVHEVhyc7CdBYT9OpygsuMFkhy1ficffdxeisIhCj6l0LHv25CA9xNxcshSSm4-OMYV-7uhtJ6qTMVS2ri5y8EAgAC6ZBjMqcoi86Z_p25GBnA)**\nFigure 2: The main page of the GRIT-realtime site, showcasing the graphs with drop-down menu’s as well as simple database stats (three boxes across the top).\n\nCurrently, grt is used for curation poster presentations (both the front-end and the API have been used for data) as well as for the current genome note pipeline (as by default, grt parses much of the data that the genome note writer needs to complete a note). This data, as it is real-world post-curation data, can be used to imply the relative difficulty of genomic curation of the clades (see figure 3, where the Boxplot shows how many changes are made to an assembly of any clade), currently as some clades a represented by a low number of genomes there maybe an inherent sample bias towards the easier to assemble and curate (currently, those which are poorly assembled and non-curatable are re-submitted for sequencing and are not included in grt).\n\n### My Contribution\n\n### Future Work\n\n### Evidence of Team work","lastmodified":"2022-12-16T13:05:37.539835742Z","tags":null},"/Portfolio-Pieces/Real-world-patterns-in-data":{"title":"Real-world patterns in data","content":"\nContribution:: Nextflow DSL2, Python 3.9, bash\n\nWorking with:: ToL\n\nTopic:; Collaborative Projects, Decision making, Data science\n\nKSBs:: K3-3\n\n---\n\nDescription:: Patterns found in real-world data","lastmodified":"2022-12-16T13:05:37.539835742Z","tags":null},"/Portfolio-Pieces/TeloSearch":{"title":"","content":"\n\nGitHub:: [https://github.com/AlanTracey99/TeloSearch](https://github.com/AlanTracey99/TeloSearch)\n\nContribution:: Nextflow DSL2, Python 3.9, bash\n\nWorking with:: AT (colleague at Sanger)\n\nTopic:: Collaborative Project, Scaling a project to meet organisational goals\n\nKSBs::\n\n---\n\nDescription:: A pipeline to find putative telomeric sequence in good quality scaffolded assemblies\n\n### The Project\nThe TeloSearch project was originally started by a member of GRIT (AT) who had written a python script to pull putative telomeres from a scaffolded genomic assembly. This would be a very useful tool in the curation team but would need scaling up in order to be run across the hundreds of genomic assemblies expected to move through the ToL genome engine on a weekly basis.\n\nThis project involved a significant amount of collaboration between the two of us, talking through what was required for converting a singular python script into a automatic and horizontally scalable Nextflow DSL2. This has involved creating a series of scripts—which were not originally part of the project—that handles the input, massages multiple intermediary files, creates a summary output file and takes the best putative telomere and enters it into the Jira Ticket for that assembly.\n\n### My Contribution\nMy contributions to the project consisted of writing a significant amount of the Nextflow DSL2 Pipeline as this was also being used as a way to train AT on how Nextflow works, the correct syntax as well as how to modularise a pipeline.\n\nAs we had very similar Python skills, I also helped in writing of the list comprehensions and lambda functions used in the main TeloSearch Python scripts.\n\nA number of the projects I have written whilst at Sanger have involved using the Jira-Python module, because of this I also suggested we write a module to take the final output and insert this into the ticket related to the input genome.\n\n### Future Work\nAs part of [[TreeVal]] this project will be updated, as some functions related to identifying putative sequences are too broad, and then used as part of the standard TreeVal pipeline. This will allow us to collect a database of telomeric sequences that have yet been seqeunces and further improve curation outcomes.\n\nSome parts that I could update significantly include the `jira_telo_push.py` script (found [here](https://github.com/AlanTracey99/TeloSearch/blob/main/scripts/jira_telo_push.py)), which would benfit from the use functional programming. This would reduce the amount of code and simultaneously making it easier to read.\n\nA simple example is the `get_length` funtion, this could be changed as below:\n\n```python\n# This code block can be run locally if the repo is downloaded and opened in Obsidian with the jupyter plugin installed and the python code block converted into a jupyter code block.\n\nputative_telo = 'ATTATTATT'\n\n# Current implementation\ndef get_length_current(motif):\n\t\"\"\"\n\tFunction returns the lengthe of a motif. !!! indicated no telo so\n\treturns 0.\n\t\"\"\"\n\tif motif == '!!!':\n\t\tmotif_value = 0\n\telse:\n\tmotif_value = len(motif)\n\treturn int(motif_value)\n\n# Proposed implementation\ndef get_length_proposed(motif):\n\t\"\"\"\n\tFunction returns the lengthe of a motif. !!! indicated no telo so\n\treturns 0.\n\t\"\"\"\n\treturn int(motif_value) if motif == '!!!' else len(motif)\n\nget_length_current(putative_telo)\n# 9\n\nget_length_proposed(putative_telo)\n# 9\n```\n\n### Evidence of Team work\nSome of this evidence includes where I am teaching AT how to use GitHub and teaching them the Nextflow DSL2 syntax.\n\n##### Evidence 1\nOn setting up and using GitHub - Slack Chat.\n```markdown\nDamonLBP\nOh yes, wrong word at the wrong time then say goodbye to your work. This is why you almost can't push too often.\n\nThat way you can revert any damaging changes you do\n\nAT\nyou almost want push running every 30 seconds in the background...\n\nDamonLBP  \nYep, but then pushing code to main which doesn't work is bad practise and just as likely to annoy. So branches are a safe space.\n\nAT\nok,  I need to remember that and get used to working in branches.  Would you say each branch should have a task associated with it and then when that task is done you pull it back into main?\n\n\nDamonLBP  \nYes precisely.\n\nThis is also where using GitHub Issues and the integrated KanBan board can be useful\n```\n\n\n##### Evidence 2\nOn reporting updates I have made and a discussion on further changes.\n\nPart 1 - Slack Chat\n```markdown\nDamonLBP  \nMorning Alan,  \nThere's not much i'll be able to do today due to university stuff. But i thought i'd let you know that the JIRA integration works... kind of. Running the script outside of the pipeline works and posts to GRIT-280 but inside the pipeline it fails due to 'Being outside of the Sanger Network' So this maybe a systems issue. I've detailed what I can here: [https://github.com/AlanTracey99/TeloSearch/issues/2](https://github.com/AlanTracey99/TeloSearch/issues/2)It wouldn't be alot of work to make my script take the cannon and noncannon files and spit out what it thinks is best and run it separately but it would be a pain.\n\nAT\nThanks Damon - sounds like progress.  Happy to chat about the best way to utilise the results if you want at some point...\n\nDamonLBP\nIt is done, the pipeline now passes to JIRA. The python script needed to pass the JIRA request through the sanger cache system in order to connect.\n\nAT \nNice!\nAre there any telo-populated tickets?\n\nDamonLBP\nI did GRIT-470, you can see where the changes occurred at the bottom of the history tab. I'm changing it so the length is actually the length of the sequence, currently measuring the wrong bit of the report.\n\nPart 2 (see below) was attached.\n\n```\n\nPart 2 - Screenshot of the incorrect upload to JIRA\n![[images/evidence_of_jira_integration_telosearch.png]]\n\nPart 3 - Slack Chat (following on from Part 2)\n```markdown\nAT\nonly thing I don't like is 'CAN' looks like DNA sequence, eg CA[*]\n\nDamonLBP  \nThat is a fair point\n\nAT\nnot sure why it say length 3 - but I think from what you said above that you're fixing that\n\nDamonLBP  \nI put an argument in the wrong place, so it was measuring CAN. That's fixed now, although i've managed to kill my connection to the farm.\n\nAT\nok.  Just so you know, Bethan has a hymenopteran with 2 motifs, one length 9 and one length 5 - how will you deal with this?\n\nDamonLBP  \nAt the minute, it won't. It is taking the top result and using that.  \nNeed to sort out the logic for which to pick\n\nAT \nI think we need to be able to pick and deal with multiple motifs\n\nIt can be the biological reality\n\nDamonLBP  \nYes i thought so, but at the time I was just focused on just getting the Jira posting to work.\n\nWhat if I were to change CAN and NONCAN to ! and ? respectively. I think those would make sense and also makes clear what sequence to use. It'll just make it easier for me to parse it for downstream.\n\nAT\nsounds ok - you may want to send an explanation to the curators at some point?\n\nDamonLBP\nSure as soon as it hits production. I'm writing it up on the README too.\n```","lastmodified":"2022-12-16T13:05:37.543835841Z","tags":null},"/Work-based-Projects/ONT-Assembly":{"title":"","content":"","lastmodified":"2022-12-16T13:05:37.543835841Z","tags":null},"/Work-based-Projects/TreeVal":{"title":"","content":"\n\n---\nDescription:: A gEVAL replacement, written in NextFlow and Python3","lastmodified":"2022-12-16T13:05:37.543835841Z","tags":null},"/Work-based-Projects/Work-based-Project-Homepage":{"title":"","content":"\n## Portfolio Pieces\nTable generated via the Templater and Dataview template: [[templates/workbased_projects]].\n\n| File                                                                             | Date          | Description                                                                          |\n| -------------------------------------------------------------------------------- | ------------- | ------------------------------------------------------------------------------------ |\n| [[Work-based Projects/gEVAL Data Cleaner.md\\|gEVAL Data Cleaner]]                | 50@16-12-2022 | A python script to download and parse ensembl and ncbi genomic data.                 |\n| [[Portfolio Pieces/TeloSearch.md\\|TeloSearch]]                                   | 50@16-12-2022 | A pipeline to find putative telomeric sequence in good quality scaffolded assemblies |\n| [[Portfolio Pieces/GRIT-realtime.md\\|GRIT-realtime]]                             | 50@16-12-2022 | A Full-stack project to generate graphical summaries of post-curation data           |\n| [[Portfolio Pieces/Data driven decision making.md\\|Data driven decision making]] | 50@16-12-2022 | How data has effected how a project has gone forward.                                |\n| [[Work-based Projects/TreeVal.md\\|TreeVal]]                                      | 50@16-12-2022 | A gEVAL replacement, written in NextFlow and Python3                                 |\n\n\n\n\n\n## Genome And Assembly Curation\n| Project | Description | Status | Link |\n|---|---|---|---|\n| iyTipFemo1_1 | _Tiphia femorata_ | Done | |\n","lastmodified":"2022-12-16T13:05:37.543835841Z","tags":null},"/Work-based-Projects/gEVAL-Data-Cleaner":{"title":"gEVAL Data Cleaner","content":"\nGitHub::\n\nContribution::\n\nWorking with::\n\nTopic::\n\nKSBs::\n\n---\nDescription:: A python script to download and parse ensembl and ncbi genomic data.\n\n### The Project\n\n### My Contribution\n\n### Future Plans\n\n### Evidence\n","lastmodified":"2022-12-16T13:05:37.543835841Z","tags":null}}