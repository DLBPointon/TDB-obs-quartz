{"/":{"title":"The Dyslexic Bioinformatician","content":"\n## About me\nHi I'm Damon, a year 4 BSc Data Science (Bioinformatics) apprentice working in the ToLa (Tree of Life Assembly team) at the Wellcome Genome Campus in Hinxton.\n\nThis blog will be used as evidence of learning in a final year portfolio.\n\n## Contents\n\n| Link | Description | \n|-----|-----|\n| [[Computer Science/University and CS Homepage]] | My university blog-style notes including Portfolio work |\n| [[Work-based Projects/Work-based Project Homepage]] | Notes on work-based projects |\n| [[Personal Projects/Personal Project Homepage]] | Notes on my personal \"for fun\" projects | \n| [[Languages and Technologies/Languages and Technologies Homepage]] | Notes on the different technologies and languages I've learned |\n| [[Templates for Site Generation]] | Template Modals used for generating tables and page outlines |\n\n#### How is this hosted?\nThis blog is written with Obsidian and hosted on GitHub Pages via [Quartz](https://github.com/jackyzha0/quartz)","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Computer-Science/University-and-CS-Homepage":{"title":"","content":"### University Notes\nFor Future Update\n\n### Portfolio Pieces\nAs a note, any GitHub commits reported as either dp24 or DLBPointon are my work. dp24 is a work based account and DLBPointon is my personal account.\n\nThese peices are for use in the Anglia Ruskin University BSc Data Science (Bioinformatics) End Point Assessment.\n\nTable generated via the Templater and Dataview template: [[templates/portfolio_projects_table]].\n\n| File                                                                                                | Date          | Description                                                                                                                                                                                                                                                          | Type                                                                                         | KSBs                       |\n| --------------------------------------------------------------------------------------------------- | ------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------- | -------------------------- |\n| [[Work-based Projects/Curation of idCriBerb1.md\\|Curation of idCriBerb1]]                           | 05@3-02-2022  | Detailing the curation of idCriBerb1                                                                                                                                                                                                                                 | \u003cul\u003e\u003cli\u003eCuration\u003c/li\u003e\u003c/ul\u003e                                                                   | K5-5, K3-3, S6, S7, B3     |\n| [[Work-based Projects/Curation of iyTipFemo1.md\\|Curation of iyTipFemo1]]                           | 51@22-12-2022 | How I have curated the reference genome for _Tiphia femorata_.                                                                                                                                                                                                       | \u003cul\u003e\u003cli\u003eCuration\u003c/li\u003e\u003c/ul\u003e                                                                   | K5-5, K3-3, S6, S7, B3     |\n| [[Portfolio Pieces/Data driven decision making.md\\|Data driven decision making]]                    | 50@16-12-2022 | How data has effected how a project has gone forward.                                                                                                                                                                                                                | \u003cul\u003e\u003cli\u003eLearning\u003c/li\u003e\u003c/ul\u003e                                                                   | K3-3                       |\n| [[Portfolio Pieces/Ethics and Compliance.md\\|Ethics and Compliance]]                                | 01@03-01-2023 | What is the Nagoya Protocol and how it effects DTOL work.                                                                                                                                                                                                            | \u003cul\u003e\u003cli\u003eLearning\u003c/li\u003e\u003c/ul\u003e                                                                   | K2, B4                     |\n| [[Portfolio Pieces/Forefront of Datascience.md\\|Forefront of Datascience]]                          | 50@16-12-2022 | How I have continued learning and pushing my skills to improve organisation processes as well as my own personal projects, this involved keeping up with new technologies as well as learning technologies which many not necessarily be part of my day-to-day work. | \u003cul\u003e\u003cli\u003eLearning\u003c/li\u003e\u003c/ul\u003e                                                                   | B1                         |\n| [[Portfolio Pieces/GRIT-realtime.md\\|GRIT-realtime]]                                                | 50@16-12-2022 | A Full-stack project to generate graphical summaries of post-curation data                                                                                                                                                                                           | \u003cul\u003e\u003cli\u003eFull-stack Project\u003c/li\u003e\u003cli\u003eDatabase-PostreSQL\u003c/li\u003e\u003cli\u003eSoftware Development\u003c/li\u003e\u003c/ul\u003e | K5-3, S6, B1, K3-3, B1, B6 |\n| [[Portfolio Pieces/Positive engagements.md\\|Positive engagements]]                                  | 01@05-01-2023 | How have I attempted to improve my attitude in a diverse working group?                                                                                                                                                                                              | \u003cul\u003e\u003cli\u003eLearning\u003c/li\u003e\u003c/ul\u003e                                                                   | B2                         |\n| [[Work-based Projects/Slack Bots.md\\|Slack Bots]]                                                   | 01@04-01-2023 | Description of the slack bots developed to better inform GRIT and GEVAL-builders                                                                                                                                                                                     | \u003cul\u003e\u003cli\u003eSoftware Development\u003c/li\u003e\u003cli\u003eBot\u003c/li\u003e\u003c/ul\u003e                                           | B1                         |\n| [[Portfolio Pieces/TeloSearch.md\\|TeloSearch]]                                                      | 50@16-12-2022 | A pipeline to find putative telomeric sequence in good quality scaffolded assemblies                                                                                                                                                                                 | \u003cul\u003e\u003cli\u003ePipeline\u003c/li\u003e\u003cli\u003eSoftware Development\u003c/li\u003e\u003c/ul\u003e                                      | S6, S7, B1, B3, B4         |\n| [[Work-based Projects/TreeVal - md team and tracking time.md\\|TreeVal - md team and tracking time]] | 50@16-12-2022 | A Nextflow DSL2 pipeline + Jbrowse Front end to replace gEVAL                                                                                                                                                                                                        | \u003cul\u003e\u003cli\u003ePipeline\u003c/li\u003e\u003cli\u003eSoftware Development\u003c/li\u003e\u003c/ul\u003e                                      | S6, S7, B1, B2, B3, B4, B6 |\n\n\n\n\n\n\n\n","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Languages-and-Technologies/Languages-and-Technologies-Homepage":{"title":"","content":"\n\n| Language | Description |\n|--|--|\n| Python 3 | My first language, generalist\n| JavaScript | Used in multiple projects, web focused\n| Bash | Language of the command line |\n| Nextflow | Written in Groovy, Data science pipelining language |\n","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Personal-Projects/Better-metadata-parsing-Jellyfin-youtube":{"title":"","content":"# Better metadata parsing - Jellyfin-youtube\n\nRepo::\nDescription:: A simple python script to parse filenames or a info.json to improve file organisation of videos downloaded for educational use.\n\n## What is it for?\n\nThe pre-existing youtube metadata plugin doesn't meet my requirements or is possibly broken (according to recent issues), I think it should be possible to a simple python script to parse a .info.json file and/or the filename to generate better outcome.\n\n---\n## What will it be used for?\n\n\n---\n## What do i need to do this? What cost?\n\n\n---\n## What do i need to learn? \n\n\n---\n## Resources","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Personal-Projects/NCBI-Taxonomy-QuickAdd":{"title":"","content":"\nDescription:: An Obsidian Plugin for NCBI taxonomy data.\n\nBuilt whilst I was getting to documenting the organsisms I was working on in DTOL this little project allowed me to get to: know the Obsidian environment a bit better, improve my skills in JavaScript and create a local database on the bugs I like (bees and wasps).\n\n#### GitHub\n[Here](https://github.com/DLBPointon/QuickAdd-ncbi)\n\n#### Tech Stack\n| Technology | Docs | Implimented | Description | \n|--|--|--|--|\n| JavaScript | | Done | Language |\n| Markdown | | Done | Language |\n| Obsidian | | Done | Knowledge management software |\n\n#### Output\n```\n# Tiphia femorata\n\n## Taxonomic Data\n### TaxID:: 330862\n### RankOfQuery:: species\n### Lineage:: [[Eukaryota]], [[Metazoa]], [[Ecdysozoa]], [[Arthropoda]],\n                [[Hexapoda]], [[Insecta]], [[Pterygota]], [[Neoptera]],\n                [[Endopterygota]], [[Hymenoptera]], [[Apocrita]], [[Aculeata]],\n                [[Tiphioidea]], [[Tiphiidae]], [[Tiphiinae]], [[Tiphia]], [[]]\n\n## Genetic Code\n### GeneticCode:: 1\n### MitoGeneticCode:: 5\n```\n\nThis allows for each segment of the lineage to create a linked mention to another note and using a Plugin called DataView you would be able to collate all Aprocrita, for example, you are working on.\n\n#### Future work\n\n[[NCBI-Notes]]\nCurrently the scope of this pseudo plugin is limited to the taxonomic data that ncbi has on an organism, this is just a fraction of the whole API. I would like to create a stand alone Plugin that can query the API and generate a note with data denoted in a template.\n\nI'm aware that the user base for such a Plugin will be limited to the handful of bioinformaticians that use Obsidian but it gives the chance to understand the Obsidian API, JavaScript and NCBI API.","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Personal-Projects/Personal-Project-Homepage":{"title":"","content":"A page for the projects i'm working on or planning to work on.\n\n## In Active Development\n\n| File                                                                                                            | Date          | Description                                                                                                                                                                  | Type                                                                                                    | Status                           |\n| --------------------------------------------------------------------------------------------------------------- | ------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- | -------------------------------- |\n| [[Personal Projects/Better metadata parsing - Jellyfin-youtube.md\\|Better metadata parsing - Jellyfin-youtube]] | 01@04-38-2023 | A simple python script to parse filenames or a info.json to improve file organisation of videos downloaded for educational use.                                              | \u003cul\u003e\u003cli\u003eSoftware\u003c/li\u003e\u003c/ul\u003e                                                                              | Waiting on Time                  |\n| [[Personal Projects/NCBI Taxonomy QuickAdd.md\\|NCBI Taxonomy QuickAdd]]                                         | NA            | An Obsidian Plugin for NCBI taxonomy data.                                                                                                                                   | \u003cul\u003e\u003cli\u003eSoftware\u003c/li\u003e\u003c/ul\u003e                                                                              | Completed                        |\n| [[Personal Projects/PiStack.md\\|PiStack]]                                                                       | NA            | A 4 node Kubernetes Cluster.                                                                                                                                                 | \u003cul\u003e\u003cli\u003eHardware\u003c/li\u003e\u003cli\u003eSoftware\u003c/li\u003e\u003cli\u003eLearning\u003c/li\u003e\u003c/ul\u003e                                            | Completed (Not in Use)           |\n| [[Personal Projects/PuffCrust.md\\|PuffCrust]]                                                                   | NA            | My [[Vault]]/ShortCrust version 2.                                                                                                                                           | \u003cul\u003e\u003cli\u003eHardware\u003c/li\u003e\u003cli\u003eSoftware\u003c/li\u003e\u003cli\u003eLearning\u003c/li\u003e\u003c/ul\u003e                                            | Waiting on Time                  |\n| [[Personal Projects/TMDB.md\\|TMDB]]                                                                             | NA            | The Traumatic Media DataBase is a project I started in 2021 in order to provide a simple way to search for media which may have a scenes that could be considered traumatic. | \u003cul\u003e\u003cli\u003eSoftware\u003c/li\u003e\u003cli\u003eDockerisation\u003c/li\u003e\u003cli\u003eLearning\u003c/li\u003e\u003cli\u003eNetworking\u003c/li\u003e\u003cli\u003eDatabasing\u003c/li\u003e\u003c/ul\u003e | Needs more Research and Dev Time |\n| [[Personal Projects/Vault.md\\|Vault]]                                                                           | NA            | A Raspberry Pi4 4gb based NAS using OMV6 and Docker, that I also call ShortCrust.                                                                                            | \u003cul\u003e\u003cli\u003eHardware\u003c/li\u003e\u003cli\u003eSoftware\u003c/li\u003e\u003cli\u003eContainerisation\u003c/li\u003e\u003cli\u003eNetworking\u003c/li\u003e\u003c/ul\u003e                 | Completed                        |\n\n\n\n\n## Projects in waiting\n\n| Project | Description | Type | Stage |\n|---|---|---|---|\n| System Plot | An Obsidian Plugin, a different way of visualising folder-file relationships | Software | Waiting on Time |\n| NCBI-Notes | An Obsidian Plugin, a stand alone plugin that enables searching on the NCBI API in Obsidian | Software | Waiting on Time |\n| CyberDeck | I've fallen in love with the idea of a Raspberry Pi Cyber Deck and would love to get involved in the community | Hardware / Software | Waiting on Time and Money |\n\n\n","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Personal-Projects/PiStack":{"title":"","content":"\nDescription:: A 4 node Kubernetes Cluster.","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Personal-Projects/PuffCrust":{"title":"","content":"\nDescription:: My [[Vault]]/ShortCrust version 2. \n\nMany of the services from Vault will be ported over and all run on the same machine, this will of course be somewhat of a headache as the containers will have to be updated to the respective x86 container and some of the configs are not simple drag and drop.\n\n## Potential Hardware\n| Hardware | Description |\n|---|---|\n| Ryzen 3/5 G processor | Will have to buy ~£100|\n| 16Gb Crucial Ballistix | DDR4 3200Mhz - Spares |\n| B450 Aurous ATX motherboard | Spare from toubleshooting GPU fault, need to check wether working / ITX would be nicer |\n| Corsair 750 Gold PSU | Something smaller would be nicer from an efficiency POV |\n| Case | unknown yet, would like something with a few hot swap cages though |\n| External HDD | 4Tb |\n| External HDD \\*2/3 | 10 Tb |\n\n![[Personal Projects/Vault#Services]]","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Personal-Projects/TMDB":{"title":"","content":"\nDescription:: The Traumatic Media DataBase is a project I started in 2021 in order to provide a simple way to search for media which may have a scenes that could be considered traumatic. \n\nThis was inspired through seeing the effects of Birth Trauma on multiple woman I personally know and, through my wife, the effect that the trope of suprise traumatic birth scenes in popular media can have.\n\nMy plan for this project is to make a robust full stack project and then \"give\" it to the Birth Trauma Association to aid in raising awareness. This project has also been built with other traumatic events in mind and can be expanding on when needed.\n\n#### GitHub (Currently Private)\n[TMDB Project Page](https://github.com/DLBPointon/tmdb_project)\n\n#### Tech Stack\n| Technology | Docs | Implimented | Description | \n|--|--|--|--|\n| Angular |  |  | Single Page Application |\n| React | | | Should i change to React as it is much more popular? |\n| PostgreSQL |  |  | The backend database |\n| PostgREST |  |  | A database - API layer |\n\n## Issues\n\n### Issue 1 - Schema\nMain issue stopping further work is the database schema, there is an issue between the table main_2_traum_ref (which assigns the media to multiple trauma events) and the traumatic_table (which details the type of trauma (which is in no particular order)).\n\n```\ndb_1   | 2021-09-30 07:31:22.803 UTC [91] ERROR:  insert or update on table \"main_2_traum_ref\" violates foreign key constraint \"traumatic\"\ndb_1   | 2021-09-30 07:31:22.803 UTC [91] DETAIL:  Key (traum_pk)=(1) is not present in table \"traumatic_table\".\ndb_1   | 2021-09-30 07:31:22.803 UTC [91] STATEMENT:  COPY main_2_traum_ref FROM '/var/lib/postgresql/tmdb/main_2_traum_ref.tsv' CSV HEADER DELIMITER E'\\t' NULL '';\ndb_1   | psql:/docker-entrypoint-initdb.d/20_db_fill.sql:5: ERROR:  insert or update on table \"main_2_traum_ref\" violates foreign key constraint \"traumatic\"\ndb_1   | DETAIL:  Key (traum_pk)=(1) is not present in table \"traumatic_table\".\n```\n\nOnly enough, talking with multiple other people that have worked on databases, the actual code is correct, but something seems to be getting in the way.\n\n#### Fix\nI think the database just needs redesigning, it isn't as optimal as it could be.\n\n### Issue 2 - Hosting\n\nI could self-host the application on [[PiStack]], but will there be an issue with scaling as I will be taking this to the Birth Trauma Association, are 4 Pi's enough? \n\nSecurity, how would I secure a self-hosted app like this? Is the domain provider able to secure this? Nginx Reverse Proxy is able to do much of this, will ISP allow?\n\n#### Fix\nMuch more reading, talk to some people who know much more in this topic.\n\n### Issue 3 - Adding new events\n\nI can't sit at a computer verifying new additions, but I also can't have a completely open DB. Security would be a nightmare as, lets face it people would attack it. \n\nDo I implement a login feature knowing that it would put some people off logging media?\n\nThis would require JWS tokens and I just don't know enough in the field.\n\n### Fix \nMuch more reading, talk to some people who know much more in this topic.\n\n### Issue 4 - Scoring\nWe cannot score based on the trauma, it creates a heirarchy of \"this trauma is more traumatic than that one\". Trauma is trauma and cannot be scored. So I propose a method based on the number of \"events\" / length of time to consume the media or maybe number of \"events\" per hour/page. This could be calculated in the DB or on the fly with some JavaScript.\n\nA score based on the number of triggers, length of film/book/show as an indicator of whether you should watch it Maybe something like in grt-realtime, javascript traffic light for if trigger score above x then give traffic light colour.","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Personal-Projects/Vault":{"title":"","content":"\nDescription:: A Raspberry Pi4 4gb based NAS using OMV6 and Docker, that I also call ShortCrust.\n\nThe number of containers now running on this has occasionally led to some major slow downs and website freezing. Because of this and as I have a number of computer spare parts now, i think i'll just update the entire infrastructure of this project [[PuffCrust]]. As an intermediary step I have added a portainer agent (A Raspberry Pi 4 called Docker-1, D1) to expand the docker capabilities of the Vault, this is now effectively a 1x head and 1x node cluster.\n\n## Hardware\n| Hardware | Description |\n|---|---|\n|2 x Raspberry Pi 4 | 4Gb + 32Gb SD card |\n| External HDD | 4Tb |\n| External HDD | 10 Tb |\n\n## Services\n| Service | Port | Description | Site |\n|---|---|---| --- |\n| Open Media Vault 6 | 10.0.0.2 | The NAS operating system | [OMV](https://www.openmediavault.org/)\n| Homepage | D1:3100 | A Homepage to collect all services | [Homepage GH](https://github.com/benphelps/homepage)\n| Portainer | :9000 | Docker manager | [Portainer](https://www.portainer.io/)\n| Plex | :32400 | Media viewer | [Plex Docker](https://github.com/linuxserver/docker-plex)\n| Jellyfin | :8096 | Media viewer (FOSS alt to Plex) | [Jellyfin Docs]() \n| Tautulli | :8181 | Plex Stat Tracker | [Tautulli Docker](https://hub.docker.com/r/tautulli/tautulli)\n| Airsonic |  :4040 | Local Music Player | [Airsonic](https://hub.docker.com/r/linuxserver/advanced-airsonic)\n| Kavita | :5000 | Comic and Book Viewer | [Kavita Wiki](https://wiki.kavitareader.com/en)\n| meTube | :9090 | Video Download Server | [MeTube GH](https://github.com/alexta69/metube)\n| Ubuntu | :1234 | Dev environment | [Ubuntu Docker](https://hub.docker.com/_/ubuntu)\n| Nginx Proxy Manager | D1:86 | Proxy Manager | NPM |\n| Obsidian-remote | D1:NPM:8900 | Home accessible Obsidian Instance | [obs-remote](https://github.com/sytone/obsidian-remote)\n\n\n\n","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Portfolio-Pieces/Data-driven-decision-making":{"title":"Data driven decision making","content":"\nContribution: Nextflow DSL2, Python 3.9, bash\n\nWorking with: ToL\n\nTopic: Collaborative Projects, Decision making, Data science\n\nKSBs:: K3-3\n\n---\n\nDescription:: How data has effected how a project has gone forward.\n\nThrough my work in DTOL, data driven decision making has been ubiquitous. Through Tree Of Life Research and Development (ToL RnD) meetings we see the effects of data driven decision making on:\n\n- The Core Labs team and their experiments in attemping to improve sequencing pipelines, and the effect on sequencing yield due to the complex genomes of polyploid plants and highly repetitive genomes.\n\n- The Faculty Research groups in where they must decide on the best ways in which to massage their data to produce informative results. The Merian Unit Analysis (not yet published), which is being added to the [[TreeVal - md team and tracking time]] Project, needed iterative refinement to best identify putative ancestral units. This will go on to be used in [[TreeVal - md team and tracking time]] to better improve both curation and Lepidopteran genetics.\n\n- GRIT require the use of a multitude of data in order to correctly identify scaffolds which may require breaking, joining or even removing depending on a variety of features such as: coverage changes, telomeric sequence, and strength of HiC signal. All of these impact the quality of the final genomic assembly.\n\t-  [[Work-based Projects/Curation of iyTipFemo1]]\n\t- [[Work-based Projects/Curation of idCriBerb1]]\n\n\tThis data is also entered into Jira, for ingestion into other data-driven projects, such as [[GRIT-realtime]]. This takes the curation data and collates it into a form usable for management decisions and publications.\n\n- ToLa has been testing the use of Ultra-Low Input sequencing methods and comparing these against the current suite of sequencing methods already in use at Sanger. This is acheived by taking the raw reads from both methods, assembling the filtered reads and then collecting stats on those final assemblies.\n\t- Image of assembly graphs from ksenia?\n\n- [[TreeVal - md team and tracking time]] has required data driven decision making too, the documentation for some methods and functions---performed by the gEVAL/ensembl database---have been lost and so could not be replicated in JBrowse (the front-end component of TreeVal). The selfcomp (Self complementary sequence) track is a prime example, Minimap2 resullts in blocks of hits which has required iterative refinements to mimic the results shown on gEVAL.\n\t- Images of gEVALs output as well as JBrowse pre and post selfcomp fix.\n\n\tThis project has also involved close co-operation with GRIT in order to ensure that the curators could reach the same conclusions given the gEVAL build or the TreeVal build. ","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Portfolio-Pieces/Ethics-and-Compliance":{"title":"Ethics and Compliance","content":"\nGitHub:: NA\n\nContribution:: NA\n\nWorking with:: DTOL, VGP\n\nTopic:: Data governense and data security\n\nKSBs:: K2, B4\n\n---\nDescription:: What is the Nagoya Protocol and how it effects DTOL work.\n\n### The Project\nDTOL does not just work with data obtained from Britain and the British Isles, the project is also partnered with the Vetebrate Genomes Project (VGP) a North America led project which will sometimes rely on Sanger for the sequencing, assembly and curation of certain rare organisms.\n\nAs this partnership involves the international distribution of a genetic resource (e.g. biological material including plant, animal, microbial or any manterial in which contains the functional units of heredity. This excludes human genetic material.) in order to extract a genomic resource , an important protocol comes into play: The Nagoya Protocol.\n\n##### What is Nagoya?\nThe Nagoya Protocol is a framework developed in the Convention on Biological Diversity and is used to implement a specific objective:\n\n\u003e The fair and equitable sharing of benefits arising out of the utilisation of genetic resources.\n\u003e - GovUK (2022)\n\nThis objective makes it essential that anyone who extracts data from a genetic resource makes said data availble to those who supplied the original material. In the case of Sanger it is therefore required that the data extracted from the genetic resources is shared with the VGP, and in the international arena the protocol was originally drafted in order to stop the exploitation of Indigenous peoples (their land and waters) by companies (forcing them to at least share the profits of discovery).\n\nIn order for work to begin on a genetic resource\n\n##### The affect of Nagoya on Research\nThe Nagoya Protocol is undoubtably a step in the right direction for open science, collaboration and ensuring that indigenous peoples and their land are not abused by those profiting off of their genetic resourses (also known as biopiracy, [one such case](https://www.nature.com/articles/d41586-019-03374-x) in 2019, forces a company to share its profits with the Indigenous San and Khoi people of Southern Africa).\n\nThe beurocratic nature of such protocols does however slow reseach, each genetic resource must be well documented and approved by the relavent government (the onus is on the recipient of the sample to perform due diligence and prove that the sample has been collected properly and follows the Nagoya Protocol). The amount of time required to fullfill these requirements can leave samples, for an extended period of time, on ice (sometimes literally) which may degrade any genetic material.\n\nThis can decrease the quality of research performed unless sample collection and shipping can be planned in advance, something which cannot be done in the case of rare protected organisms. In these cases, the sameple may have to be prepared and stored in sub-par conditions which may degrade any genetic material that is present, depending on the method used. Ultimately this can result in genetic material that is degraded and lessens the impact of research in there respective field, conservation genomics or genetic surviellance, such as in malaria and mosquito tracking.\n\nThe entirety of the Nagoya protocol may also change in the coming years as there is a growing push to include digital data, see table 1. How this would effect online repositories such as NCBI and ensembl, which share digital genomic data internationally, is unclear and woud hopefully come under a blanket Nagoya certificate such like copyright notices in a GitHub repo.\n\n| Paper | Author | Sentiment | Link to article |\n| --- | --- | --- | --- |\n|  Including Digital Sequence Data in the Nagoya Protocol Can Promote Data Sharing | Ambler. J | For Inclusion | [https://doi.org/10.1016/j.tibtech.2020.06.009](https://doi.org/10.1016/j.tibtech.2020.06.009 \"Persistent link using digital object identifier\") |\n|  Global accessibility of DSI in easy-to-access databases | Sanger | Against | https://www.sanger.ac.uk/wp-content/uploads/jul2019__wellcome_sanger_institute_dsi_submission.pdf |\n|  Digital Sequence Information and the Nagoya Protocol | ICC | Against | https://iccwbo.org/publication/digital-sequence-information-and-the-nagoya-protocol/ |\n| Response from the Royal Society of Biology | Royal Society of Biology | Against | https://www.rsb.org.uk/images/article/policy/RSB_response_Defra_call_for_comment_on_DSI_and_Nagoya_protocol.pdf |\n|  When the cure kills—CBD limits biodiversity research | Prathapan, KD | Against | https://doi.org/10.1126/science.aat9844 |\n|  Public health implications of the implementation of the Nagoya Protocol | IFPMA | Against | https://www.ifpma.org/subtopics/public-health-implications-of-the-implementation-of-the-nagoya-protocol/ |\n| # Multilateral benefit-sharing from digital sequence information will support both science and biodiversity conservation | Scholz, AM | For Inclusion and offers a compromise | https://www.nature.com/articles/s41467-022-28594-0 |\nTable 1: A list of articles that have made arguments for or against expanding the Nagoya protocols to include digital data.\n\nThe arguments in the cites papers of Table 1 centre around one major theme, this is that modern science already applies it self to open science where databases freely provide genomic data to all and regulation of this will hamper the very fabric of open science. Essentially the beurecratic machine would hamper novel research and force companies to pay a share of the profits to the country in which the organism of interest originated from. \n\nThose that are for this measure however are typically based in the Global South where their genetic resources have been abused by non-indigenous people, e.g. corporations, and they have not received any compensation for what is their genetic resource.\n\nThese are quite standard arguments, however, the implications get more interesting the deeper it is researched. Digital Sequence Information (DSI), the digital genomic data, is not propperly defined and makes no mention of the nuances of genetic data or even of the distribution of species. Many species do not reside within the borders of an individual country. In these cases, is the financial renumberation divided between these countries? What about genes which are closely related and shared between a number of species? \n\nThis is a complex topic and whilst its aim of essentially ending biopiracy is a noble cause, the current proposals are too prehibitive to the open science databases that have been created over the past near 30 years. I beleive there is case for penalising corporations which abuse the lands genetic resources without renumeration for the local peoples but the current proposals put the onus on the databases to essentially track and control the distribution of the data.\n\nThe potential of including DSI into the Nagoya Protocol has already hindered the work currently on-going at Sanger. Noted in the article, Global accessibility of DSI in easy-to-access databases seen in table 1, partnership programs in Gabon and Ethiopia have stalled due to uncertainties in the current Nagoya protocol framework. This program supplied mosquito samples for MalariaGEN which we assemble and curate, which can also impact our own workflows.\n\nA key case-study relates to the project I am primarily assigned to, The Dawrin Tree of Life Project. This project is a sub-project of the multi-billion dollar Earth Biogenome Project, which aims to sequence the genomes of all 1.5 million known species of animals, plants, protozoa and fungi on Earth. As of January 2023, there are sub-projects across the majority of Earth, each relying on the principles of open science to send and retreive data for the goal of improving our knowledge in conservation genomics and understanding our ecosystems. These noble goals can only be fullfilled if the data is able to flow easily and rapidly through existing open science databases without hinerance from a third party such as a DSI enhanced Nagoya Protocol. This hinderance has the potential to irrepearably damage conservation effects and reponses the emerging threats to biodiversity.\n\n### References\nGovUK. 2022. _Regulations: The Nagoya Protocol on access and benefit sharing (ABS)_ \\[Online\\]. Accessed 03-01-2022. https://www.gov.uk/guidance/abs.","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Portfolio-Pieces/Forefront-of-Datascience":{"title":"Forefront of Datascience","content":"\nContribution:: Nextflow DSL2, Python 3.9, bash\n\nWorking with:: ToL\n\nTopic:: Curiosity, Data science\n\nKSBs:: B1\n\n---\n\nDescription:: How I have continued learning and pushing my skills to improve organisation processes as well as my own personal projects, this involved keeping up with new technologies as well as learning technologies which many not necessarily be part of my day-to-day work.\n\nOver the past three years as I have become comfortable with Sanger systems I have started to try and push my knowldedge further. I have done this by working on by:\n\n- [[TMDB]] - Updating personal projects into vue.js from HTML and JavaScript. \n\n- [[TreeVal - md team and tracking time]] \n\t- Bring amoungst the first teams at Sanger to move towards a Nextflow + NF-core standards + ToLIT standards.\n\t- Developing a new pipeline and frontend combination based on newer technology to replace the current solution as well as ship to other collaborative groups.\n\n- [[Slack Bots]] - A simple group of bots which interact with both the Slack API as well as the JIRA API in order to pull data meeting certain specifications.\n\n- In my personal time I also enjoy learning new technologies which I have incorporated into my home network. Details about this can be found here: [[Personal Projects/Personal Project Homepage]].","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Portfolio-Pieces/GRIT-realtime":{"title":"GRIT-realtime","content":"\nGitHub:: [https://github.com/DLBPointon/grt-v5](https://github.com/DLBPointon/grt-v5)\n\nContribution:: JavaScript, HTML, Python 3.9, bash, Project Management, APIs, Database\n\nWorking with:: Solo project reporting to manager\n\nTopic:: Designing new systems to meet organisational goals.\n\nKSBs:: K5-3, S6, B1, K3-3, B1, B6\n\n---\n\nDescription:: A Full-stack project to generate graphical summaries of post-curation data\n\n### The Project\nGRIT-realtime—grt, [https://grit-realtime.tol.sanger.ac.uk/](https://grit-realtime.tol.sanger.ac.uk/)—was originally developed as coursework for the Bioinformatics in the Workplace module. Prior to this project, statistics and graphs would be gathered by: downloading a csv of data, importing this into Microsoft Excel and then manually curating the data (line by line), and, then generating the statistics and graphs required for reports and papers. This resulted in a significant time sink for management and so a more modern and automated solution was required.\n\nThe project, see figure 1, uses Python 3.9 with the jira_python module to interact with the Jira Database and pull data that meets built in requirements, e.g., belongs to a GRIT project and has made it the post-curation step of the workflow.\n\nThe data is then parsed to pull the correct information from free text fields, and calculate statistics such as manual interventions per 1Gb of genome. The output tsv file, is then ingested by a PostgreSQL database which can then serve a frontend via a PostgREST API layer. The graph views can then be altered via a series of drop-down menus to tailor the view, see figure 2.\n\n![grt-v5 schematic](https://lh3.googleusercontent.com/HxWonAXDQfPcStDizOTl3BGOmcTN4hF-wwym_LW41MqfxQ31G6GywzSadzPcbuw3YesN8NUJM6neE60HTDnxxQAjbUaRPchhw-8njxkLq-W_5wFLej_X-qSUUDTntle09mH8T2XR8tJiLUSQ96m28a64tiM_SUk-KdP6yqB_v7KZ648Z4Fd3kfDc2FvIzw)\nFigure 1: An overview of the GRIT-realtime architechture. Blue is a script, Green a source of data and orange colours the webserving components.\n\n**![](https://lh4.googleusercontent.com/svXpOUgTFa12HqLgOPlmGRRTuZNFjhTJ46R6HdEP4OTkRJGZODrcYZgQ9D1uoR3mDjWX6uiIt4Uj45lnfVHEVhyc7CdBYT9OpygsuMFkhy1ficffdxeisIhCj6l0LHv25CA9xNxcshSSm4-OMYV-7uhtJ6qTMVS2ri5y8EAgAC6ZBjMqcoi86Z_p25GBnA)**\nFigure 2: The main page of the GRIT-realtime site, showcasing the graphs with drop-down menu’s as well as simple database stats (three boxes across the top).\n\nCurrently, grt is used for curation poster presentations (both the front-end and the API have been used for data) as well as for the current genome note pipeline (as by default, grt parses much of the data that the genome note writer needs to complete a note). This data, as it is real-world post-curation data, can be used to imply the relative difficulty of genomic curation of the clades (see figure 3, where the Boxplot shows how many changes are made to an assembly of any clade), currently as some clades a represented by a low number of genomes there maybe an inherent sample bias towards the easier to assemble and curate (currently, those which are poorly assembled and non-curatable are re-submitted for sequencing and are not included in grt).\n\n### My Contribution\nI built the entirty of grt, originally as coursework for the Bioinformatics in the Workplace. The original was based in R for display in RShiny and is still hosted [here](https://grit-realtime.shinyapps.io/scripts/), the loading time alone (around 5 minutes) required a different approach and so the aforementioned containerised version was produced. This was also during a time where Sanger-IT were encouraging people to move away from RShiny due to the amount of time taken to compile a Shiny Container as well as the poor scaling and porformance of the framework.\n\n### Future Work\nSanger contains a group that soley work on platforms, their role over the past 3 years has been creating a ReactJS based framework for sample management throught out DTOL. As that project has grown, so have the ambitions for it. It is currently being rolled out company wide and is now based on a Sanger specific framework in which a number of projects will be converted too. This will, however, require learning ReactJS so will represent a significant learning curve from vanilla JavaScript.\n\nI will eventually be commiting grt over to this new platform, where it will be further expanded on by including [[TeloSearch]] results from Jira as well as BUSCO from [TolQC](https://tolqc.cog.sanger.ac.uk/index.html) (one of the site) and/or [[TreeVal - md team and tracking time]] to better act as a post-curation summary site.\n\n","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Portfolio-Pieces/Positive-engagements":{"title":"Positive engagements","content":"\nGitHub:: NA\n\nContribution:: Joining the SEESAW group\n\nWorking with:: SEESAW\n\nTopic:: Behaviour in diverse groups\n\nKSBs:: B2\n\n---\nDescription:: How have I attempted to improve my attitude in a diverse working group?\n\n### The Project\nWhilst working at Sanger I have worked in a heavily diverse team, with members from across the globe, however it can be easy to simply not think about the difficult situations in that some have faced to enter the Data Science field. As someone who has a specific learning dissability as well as coming from a low-socioeconomic background, I feel I have a first hand experience of this dissmissal of my struggles. However as a, somewhat, young, white, cis-gendered male, it is easy to simply not see the struggles experiences by others.\n\nFor this reason as well as to be more of an advocate for diversity I have joined the Wellcome Trust's Socio-Economic Equity Staff Network (SEESAW). This group aims to increase the awareness of how differing life experiences and unconcious biases have effected any one persons entry into there respective role. For instance, in the first session the organisers reveiled data on Sanger recruitment practices which historically showed that it is a white middle class male institution. Although this has changed dramatically in the past decade, there are still hangovers of that original homogenous mix. For example, the simple weekly pub lunch is quite common and disadvantages those from low socioeconomic backgrounds which simply cannot spend the £40-50 that a Cambridge pub lunch costs.\n\nIn the second session, the sociologist Sam Friedman gave a talk on his book 'The Class Ceiling' which analyses the role of class in the 'elite' workplaces of Britain and how those who get the top jobs typically from upper-middle-class origins.\n\nThis book is an interesting read and highlights issues the 'double disadvantage' encountered by woman and racial ethnic minorities from working-class backgrounds.\n\n\u003e“We have uncovered clear evidence – both quantitative and qualitative – that women and racial ethnic minorities from working-class backgrounds face a distinct ‘double disadvantage’ in Britain’s elite occupations, and that this inequality is often multiplicative rather than simply additive. In this way, we might see the barriers facing these groups as often more accurately constituting a denser, and less easily shattered, ‘concrete ceiling’”.\n\nA similar issue can even be found as closely to home as this Bioinformatics Degree in which the majority of those on the course are Cambridge local, unconciously reinforcing the idea that the best people for the job are local people from an area considered wealthy. Unfortunately this is an issue that is compounded by the fact that only those coming from such an area can afford to live in the area, whilst others may struggle whilst also facing the pressures of work-place social events.\n\nThese are issues which can only be fixed by intentional action, actively visiting schools (with diverse groups of speakers) to teach about what Data Science entails. Teaching that anyone and everyone can have a place in Data Science if they, and only themselves, want it. Sanger is making headway in this by visiting schools (even if only Cambridge local school as of present) and specific recruitments programs (recently announing a paid internship program for Black people wanting to enter Data Science, as it is an under represented ethnicity).\n\n### Future Plans\nTo continue my engagement in SEESAW and push for a Sanger specific working group to open a dialouge on these issues.","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Portfolio-Pieces/TeloSearch":{"title":"","content":"\n\nGitHub:: [https://github.com/AlanTracey99/TeloSearch](https://github.com/AlanTracey99/TeloSearch)\n\nContribution:: Nextflow DSL2, Python 3.9, bash\n\nWorking with:: AT (colleague at Sanger)\n\nTopic:: Collaborative Project, Scaling a project to meet organisational goals\n\nKSBs:: S6, S7, B1, B3, B4\n\n---\n\nDescription:: A pipeline to find putative telomeric sequence in good quality scaffolded assemblies\n\n### The Project\nThe TeloSearch project was originally started by a member of GRIT (AT) who had written a python script to pull putative telomeres from a scaffolded genomic assembly. This would be a very useful tool in the curation team but would need scaling up in order to be run across the hundreds of genomic assemblies expected to move through the ToL genome engine on a weekly basis.\n\nThis project involved a significant amount of collaboration between the two of us, talking through what was required for converting a singular python script into a automatic and horizontally scalable Nextflow DSL2. This has involved creating a series of scripts—which were not originally part of the project—that handles the input, massages multiple intermediary files, creates a summary output file and takes the best putative telomere and enters it into the Jira Ticket for that assembly.\n\n### My Contribution\nMy contributions to the project consisted of writing a significant amount of the Nextflow DSL2 Pipeline as this was also being used as a way to train AT on how Nextflow works, the correct syntax as well as how to modularise a pipeline.\n\nAs we had very similar Python skills, I also helped in writing of the list comprehensions and lambda functions used in the main TeloSearch Python scripts.\n\nA number of the projects I have written whilst at Sanger have involved using the Jira-Python module, because of this I also suggested we write a module to take the final output and insert this into the ticket related to the input genome.\n\n### Future Work\nAs part of [[TreeVal - md team and tracking time]] this project will be updated, as some functions related to identifying putative sequences are too broad, and then used as part of the standard TreeVal pipeline. This will allow us to collect a database of telomeric sequences that have yet been seqeunces and further improve curation outcomes.\n\nSome parts that I could update significantly include the `jira_telo_push.py` script (found [here](https://github.com/AlanTracey99/TeloSearch/blob/main/scripts/jira_telo_push.py)), which would benfit from the use functional programming. This would reduce the amount of code and simultaneously making it easier to read.\n\nA simple example is the `get_length` funtion, this could be changed as below:\n\n```python\n# This code block can be run locally if the repo is downloaded and opened in Obsidian with the jupyter plugin installed and the python code block converted into a jupyter code block.\n\nputative_telo = 'ATTATTATT'\n\n# Current implementation\ndef get_length_current(motif):\n\t\"\"\"\n\tFunction returns the lengthe of a motif. !!! indicated no telo so\n\treturns 0.\n\t\"\"\"\n\tif motif == '!!!':\n\t\tmotif_value = 0\n\telse:\n\tmotif_value = len(motif)\n\treturn int(motif_value)\n\n# Proposed implementation\ndef get_length_proposed(motif):\n\t\"\"\"\n\tFunction returns the lengthe of a motif. !!! indicated no telo so\n\treturns 0.\n\t\"\"\"\n\treturn int(motif_value) if motif == '!!!' else len(motif)\n\nget_length_current(putative_telo)\n# 9\n\nget_length_proposed(putative_telo)\n# 9\n```\n\n### Evidence of Team work\nSome of this evidence includes where I am teaching AT how to use GitHub and teaching them the Nextflow DSL2 syntax.\n\n##### Evidence 1\nOn setting up and using GitHub - Slack Chat.\n```markdown\nDamonLBP\nOh yes, wrong word at the wrong time then say goodbye to your work. This is why you almost can't push too often.\n\nThat way you can revert any damaging changes you do\n\nAT\nyou almost want push running every 30 seconds in the background...\n\nDamonLBP  \nYep, but then pushing code to main which doesn't work is bad practise and just as likely to annoy. So branches are a safe space.\n\nAT\nok,  I need to remember that and get used to working in branches.  Would you say each branch should have a task associated with it and then when that task is done you pull it back into main?\n\n\nDamonLBP  \nYes precisely.\n\nThis is also where using GitHub Issues and the integrated KanBan board can be useful\n```\n\n\n##### Evidence 2\nOn reporting updates I have made and a discussion on further changes.\n\nPart 1 - Slack Chat\n```markdown\nDamonLBP  \nMorning Alan,  \nThere's not much i'll be able to do today due to university stuff. But i thought i'd let you know that the JIRA integration works... kind of. Running the script outside of the pipeline works and posts to GRIT-280 but inside the pipeline it fails due to 'Being outside of the Sanger Network' So this maybe a systems issue. I've detailed what I can here: [https://github.com/AlanTracey99/TeloSearch/issues/2](https://github.com/AlanTracey99/TeloSearch/issues/2)It wouldn't be alot of work to make my script take the cannon and noncannon files and spit out what it thinks is best and run it separately but it would be a pain.\n\nAT\nThanks Damon - sounds like progress.  Happy to chat about the best way to utilise the results if you want at some point...\n\nDamonLBP\nIt is done, the pipeline now passes to JIRA. The python script needed to pass the JIRA request through the sanger cache system in order to connect.\n\nAT \nNice!\nAre there any telo-populated tickets?\n\nDamonLBP\nI did GRIT-470, you can see where the changes occurred at the bottom of the history tab. I'm changing it so the length is actually the length of the sequence, currently measuring the wrong bit of the report.\n\nPart 2 (see below) was attached.\n\n```\n\nPart 2 - Screenshot of the incorrect upload to JIRA\n![[images/evidence_of_jira_integration_telosearch.png]]\n\nPart 3 - Slack Chat (following on from Part 2)\n```markdown\nAT\nonly thing I don't like is 'CAN' looks like DNA sequence, eg CA[*]\n\nDamonLBP  \nThat is a fair point\n\nAT\nnot sure why it say length 3 - but I think from what you said above that you're fixing that\n\nDamonLBP  \nI put an argument in the wrong place, so it was measuring CAN. That's fixed now, although i've managed to kill my connection to the farm.\n\nAT\nok.  Just so you know, Bethan has a hymenopteran with 2 motifs, one length 9 and one length 5 - how will you deal with this?\n\nDamonLBP  \nAt the minute, it won't. It is taking the top result and using that.  \nNeed to sort out the logic for which to pick\n\nAT \nI think we need to be able to pick and deal with multiple motifs\n\nIt can be the biological reality\n\nDamonLBP  \nYes i thought so, but at the time I was just focused on just getting the Jira posting to work.\n\nWhat if I were to change CAN and NONCAN to ! and ? respectively. I think those would make sense and also makes clear what sequence to use. It'll just make it easier for me to parse it for downstream.\n\nAT\nsounds ok - you may want to send an explanation to the curators at some point?\n\nDamonLBP\nSure as soon as it hits production. I'm writing it up on the README too.\n```","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Work-based-Projects/Curation-of-idCriBerb1":{"title":"Curation of idCriBerb1","content":"\nGitHub:: NA\n\nContribution:: Curation of a reference quality genome.\n\nWorking with:: AT, JMDW\n\nTopic:: Data driven decision making, team work\n\nKSBs:: K5-5, K3-3, S6, S7, B3\n\n---\nDescription:: Detailing the curation of idCriBerb1\n\n### The Project\nThe aims of the DTOL project include the production of reference quality genomes for the 77,000 organisms that call the British Isles and Ireland their home. A part of this mamoth task is ensuring that practically anyone can perform such a task with only some help from the professional curators in GRIT.\n\nThis portfolio peice will focus on the curation attempt of [_Criorhina berberina_](https://www.ncbi.nlm.nih.gov/data-hub/taxonomy/2663927), known internally as idCriBerb1 or commonly as the Dimorphic Bearfly, a bumblebee mimic, see Figure 1.\n\n![[images/idcriberb1.png]]\nFigure 1: An image of _Criorhina berberina_, taken by Martin Anderson (2011).\n\n### My Contribution\nGenome curation is very much like working with a very complex puzzle, except each piece is a puzzle unto itself. This is best visualised with the Pretext map visualised in PretextView2 (Figure 2). Each square is currently a scaffold and the goal is to assign each to a chromosome using off-diagonal signals (which infer association, depending on the brightness of the colour), coverage, HiGlass (a higher resolution HiC data visualiser, which does not allow editing of the map) and gEVAL analysis (which includes alignments to closely related organisms, telomeric signals, gaps and more). Using this data, and along with help from a seasoned curator in GRIT, I was able to produce around 1 curation Pretext Map, this is a separate map to the pre-curation Pretext map with changes. After consulting with a second member of the curation team, there were some large scale structural errors I had missed whilst correcting the smaller ones, see Figure 3. This required me to go back to the pre-curation map to make the additional changes which were evidenced with gap information from gEVAL (this gives evidence for making a break).\n\n![[images/idCriBerb-precuration.png]]\nFigure 2: The pre-curation pretext map, each square is a scaffold and the diagonal line is a linearised 2d representation of HiC data which when used with other data such as coverage graphs (shown as the line plot at the bottom of the figure) can be used to create a chromosome level genomic assembly.\n\n![[images/idCriBerb-curationfixes.png]]\nFigure 3: The end result of round 1 of curation, where all “obvious” changes have been made (e.g. regions of high association have been moved into their “natural” location). The above figure has also been annotated by a second curator  (JMDW), to show large scale issues with this draft curation Blue shows locations where breaks should be introduced, hinted at by the long curved signal off the diagonal (which I mistook for a centromeric signal). Green points towards two scaffolds which need to be swapped around and yellow covering a region that requires “flipping” as it is currently inverted. The colour scheme has been changed from Figure 2 to increase the contrast and allow better visualisations of the association signals.\n\n![[images/idCriBerb-postcuration.png]]\nFigure 4: The fully curated assembly, the pink, red, green and blue are chromosomes 1, 2, 3 and X respectively. The white circles show centrosomal sequences, those circles off the diagonal show areas of high association (where the sequences are similar) and are reflected on the opposite side of the figure. The white line is evidence that these signals are all in line with each other, further evidencing they are repeats, their location in the chromosomes shows they are centromeric rather than telomeric (which are absent in dipterans).\n\nIn order to generate a final pretext map, the map to be saved as evidence, the pretext instance showing with the map from Figure 4 must be “dumped”. Dumping the TPF (Tile Path Format) allows for comparison between the edited genome and that in the gEVAL database (which will be pre-curation). This allows for a FASTA file to be generated which represents, what we believe to be, the fully curated genome which will go on to become the reference genome of this species, as will be the case for the majority of organisms passing through the Darwin Tree of Life Program. Using GRIT-realtime, we can view the changes made to this genome in Table 1. This shows how the removal of various types of sequence such as; haplotypic duplications, contaminants and false duplications affects the statistics of the genome. Removed sequence, in this case, was primarily haplotypic duplication which made up the smallest 22 scaffolds that sit to the right of the sex (labelled blue) chromosome in Figure 4, these have been zoomed in Figure 5.\n\n![[images/idCriBerb-haplotypicduplication.png]]\nFigure 5: A figure to better show the haplotypic duplication of the Criorhina berberina. The blue underlined chromosome is the expected X chromosome also shown in Figure 4. Boxed in white is the 22 scaffolds of haplotypic duplication, which can be seen to have some limited association with the sex chromosome.\n\n![[images/idCriBerb-grit-realtime.png]]\nFigure 6: A graph taken from [[Portfolio Pieces/GRIT-realtime]] which shows how the curation of _Criorhina berberina_, shown here as idChiBerb1, compares to other dipterans that have been curated. The Y-axis is the number of Manual interventions per GB of genome (including breaks and joins of sequence).\n\n| Category | Value |\n|---|---|\n| Sample ID | idCriBerb1 |\n| Project ID | GRIT |\n| Latin Name | _Criorhina berberina_ |\n| Prefix DL | id |\n| Prefix FL | Diptera |\n| Family Name | Xylotini |\n| Length Before (curation, bp) | 411039249 |\n| Length After (curation, bp) | 410454260 |\n| Length Change (%) | -0.1 |\n| Scaffold Number Before (curation) | 49 |\n| Scaffold Number After (curation) | 27 |\n| Scaffold Number Change (%) | -44.8 |\n| Scaffold N50 Before (curation, bp) | 85810835 |\n| Scaffold N50 After (curation, bp) | 136888952 |\n| Scaffold N50 Change (%) | 59.5 |\n| Manual Interventions | 29 |\n| Sequence to Chromosome (%) | 99.7 | \n| Chromosome Naming Style | By Size |\n| Expected Sex | Female |\n| Observed Sex | Female |\n| Curated Allosomes | X |\n| Curated Autosomes | 3 |\nTable 1: The statistics of idCriBerb1, the internal name for Criorhina berberina, collected by grit-realtime. Showing that ~0.1% of the pre-curation genome was removed to generate the curated genome. The number of scaffolds was reduced by ~44.8% whilst the scaffold N50 increased by ~59.5%.\n\nUpon final checks, this genome is then submitted to Ensembl and NCBI, the Primary assembly is found here: https://www.ncbi.nlm.nih.gov/assembly/GCA_917880715.1#/st.\n\n### Future Plans\nFuture plans include improving skills in curation and running more of the assembly-curation pipelines, such as in the case of [[Work-based Projects/Curation of iyTipFemo1]].\n\n### Evidence\n\n##### Conversation about the first draft curation\n**JMDW**\nidCriBerb.  \nYou have two misjoins in PRTXT_2 and PRTXT_3. You have connected arms of different chrms together, q1-q2 and p1-p2\n\nSee Figure 3.\n\nSome small cent sequence contigs probably can be placed but not really a problem.\n\n_Explainer: PRTXT\\_{int} is an identifier given to pre-curation chromosomes_\n\n**DLBP**\nHi JMDW,  \nI made these changes last night, i think i thought that those curved off diagonal chunks were odd centromeric signals. It also took me a while to find that first bit added to chr 2, then found it by accident, i've added a couple of other tiny bits too. But i think i'm picking at straws now.\n\n**JMDW**\nSorry. realise I didn't really explain much or even give break coords. ...\nYou are right there is association between centromeres. but that lump of contacts is real linking between the two arms of each chromosome.\nHow you did have it the linking is very weak across those bad joins.\n\n#### References\nAnderson, M. 2011.  File\\:Törneblomfluga02216.jpg \\[Online\\]. https://commons.wikimedia.org/wiki/File:T%C3%B6rneblomfluga02216.jpg. Accessed 04-01-2023","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Work-based-Projects/Curation-of-iyTipFemo1":{"title":"Curation of iyTipFemo1","content":"\nGitHub:: https://gitlab.com/wtsi-grit/rapid-curation\n\nContribution:: Curation of a reference quality genome.\n\nWorking with:: AT, JMDW, KK, MUS\n\nTopic:: Data driven decision making, team work\n\nKSBs:: K5-5, K3-3, S6, S7, B3\n\n---\nDescription:: How I have curated the reference genome for _Tiphia femorata_.\n\n### The Project\nThe aims of the DTOL project include the production of reference quality genomes for the 77,000 organisms that call the British Isles and Ireland their home. A part of this mamoth task is ensuring that practically anyone can perform such a task with only some help from the professional curators in GRIT.\n\nThis portfolio peice will focus on the curation attempt of _Tiphia femorata_, known internally as iyTipFemo1 or commonly as the beetle-killing wasp (as it is the parasitoid of the scarab beetle), see Figure 1.\n\n![[Tiphia_femorata.png]]\nFigure 1: A female _Tiphia femorata_, commonly known as the beetle-killing wasp. Picute taken by Hectonichus (2010).\n\n### My Contribution\nThe data received by myself and the other members of ToLa is \"pre-assembled\", meaning that automated pipelines have already taken the raw read data from the Sequencing Team and generated a best-guess assembly. This assembly is then evaluated by those in ToLa with the help of [TolQC](https://tolqc.cog.sanger.ac.uk/darwin/insects/Tiphia_femorata/), a website produced to collate assembly statistics as well as preliminary contamination reports and includes graphs as shown in Figure 2 and 3.\n\n![[images/iyTipFemo1-kmerplot.png]]\nFIgure 2: A Kmer multiplicity plot, that highlights a fairly well assembled diploid genome---e.g. the first red peak is \u003e50% of the larger peak and the grey peak being kmers that have been removed but have no impact on the quality of the genome\n\nThe iyTipFemo1 assembly it self was unremarkable---apart from two noticable regions of highly repetitive regions---and the size of the genome (~300MBp) was small enough that it assembled well via the automated processes, see Figure 3. This isn't a perfect process and misjoins (where contigs that do not actually need joining are joined by the assembler) may need correcting with a break (the breaking of a scaffold into it's component contigs). BUSCO was also run, as standard, on the reads for this assembly resulting in the scores found in Table 1.\n\n| Field | Score (%) |\n|---|---|\n| Completeness | 99.5% |\n| Single Copy | 99.1% |\n| Duplicate | 0.4% |\n| Fragmented | 0.1% |\n| Missing | 0.4% |\nTable 1: The BUSCO summary results showing that the assembly is estimated to be 99.5% complete with another 0.1% of sequnce being fragmented BUSCO genes. This analysis was performed across the 1367 reads that make up the iyTipFemo1 assembly.\n\nThe mitochrondial genome required more investigation. My collegue, MUS, developed a python based workflow called [MitoHiFi](https://github.com/marcelauliano/MitoHiFi), in order to tease out putative mitochondrial reads (HiFi data) via the annotation and whether or not they circularise. In the case of _T. femorata_ multiple potential mitochondrial sequences were identified, an issue that has become rather common particularly in wasp genomes.\n\n![[iytipfemo-precuration.png]]\nFigure 3: The [PretextView](https://github.com/wtsi-hpag/PretextView) of the iyTipFemo1 assembly pre-curation.\n\nIn order to narrow our search (myself, KK and MUS at this point) we employed the use of MBG (Rautiainen, 2021), CD-HIT (Fu, 2012) and Bandage (Wick, 2015). Using CD-HIT, we were able to cluster together scaffolds which were similar to a reference (a mito previously found in a wasp, determined by MitoHiFi) which resulted in two scaffolds being identified as potential mitochondrial reads, ptg00002l and ptg00003. Using MitoHiFi, MBG and Bandage it was then possible to visualise these and see their length and number of genes annotated, this required the use of multiple re-runs, modifying variables such as the clustering cut-offs in CD-HIT to ge the most optimal results. ptg00003 was then assigned as the mitochondrial sequence due to its completeness---e.g. it was a standard mitochondrial length (16kbp), carried the correct number of genes (37) and was circular---the other sequence may have been neomite (mitochondrial sequence adopted into the host genome) or a product of heteroplasmy.\n\n| Scaffold A | Scaffold B |\n|---|---|\n|scaffold_14.13  | scaffold_1.65   |\n|scaffold_2.1    | scaffold_2.20_2 |\n|scaffold_5.49   | scaffold_5.1    |\n|scaffold_6.1    | scaffold_6.20_2 |\n|scaffold_15.1   | scaffold_10.28  |\n|scaffold_16.4_1 | scaffold_11.26  |\n|scaffold_9.1    | scaffold_12.1   |\nTable 2: A table showing the scaffolds which were joined together manually. Scaffold id's ending with a '\\_1' or '\\_2' are the products of broken scaffold\n\n| Scaffold broken | At base pair position |\n| --------------- | -------- |\n| scaffold_2.20   | 9776444  |\n| scaffold_5.33   | 16411527 |\n| scaffold_6.20   | 9954728  |\n| scaffold_16.4   | 1629000  | \nTable 3: A table showing the scaffolds which required breaking and the base pair position where the break was introduced.\n\nThe curation of this assembly was relatively straight forward, requiring seven scaffold joins (see Table 2), four scaffold breaks (see Table 3), and one haplotypic sequence removal (these are moved into the assemblies haplotype file). These were all evidenced by the PretextView map (See figure 3 and 4) and HiGlass map (no longer availble due to size constraints). These contact maps make up the back bone of modern curation, allowing for high resolution interigation of HiC data (HiGlass) as well as for fast and easy manipulation of the assembly in a visual environment (PretextView).\n\n![[iytipfemo-postcuration.png]]\nFigure 4: The [PretextView](https://github.com/wtsi-hpag/PretextView)  for the iyTipFemo1 assembly, post-curation. Centromeres, if found, have also been orriented to the left of their respective chromosome.\n\nOnce these changes have been made, the PretextView is then sent to another curator for verification. If they agree that your changes were correct then the curation is complete and the last steps of GRIT involve the submittion of the final genomic fasta file for upload to NCBI. In the case of _T. femorata_ this is [here](https://www.ncbi.nlm.nih.gov/genome/?term=txid330862[Organism:noexp]) and statistics are found on [GRIT-realtime](https://grit-realtime.tol.sanger.ac.uk/table.html).\n\n![[iyTipFemo-nucmer.png]]\nFigure 5: A Nucmer plot of the pre-curation iyTipFemo1 assembly against the _Orussus abietinus_ (a sawfly, basal to wasps and bees) assembly.\n\nThe process of manually curating a genome is iterative, relying on evidence (such as the contact maps or syntenic alignments such as those produced with Nucmer, see figure 5) and can sometimes feel like playing Soduko. In any place you may need to make multiple moves and changes based on a educated guesses and these changes may be genuine or may need completely reverting.\n\nAs curation is not my typical role, this project was conducted in order to learn the whole process of assembly through the curation, this required a degree of time management whilst understanding that the curation had to be performed in a reasonable amount in order to keep the pipelines flowing. Due to this as well as time constraints with a curation colleuge, it was decided that Tuesdays and Thursdays would be \"in contact\" days where we would talk about changes needed and about potential exploratory work.\n\n### Future Plans\nI plan on furthering my skills in genomic curation by taking on more tickets in GRIT. Allowing my to get a greater grasp of the shear complexity of genomes through the Hymenopteran genomes as well as the how this compares across the three of life.\n\n### References\nFu, L., Niu, B., Zhu, Z., Wu, S., Li, W. 2012. CD-HIT: accelerated for clustering the next-generation sequencing data. _Bioinformatics_. 28(23). pp. 3150–3152. DOI: [10.1093/bioinformatics/bts565](https://doi.org/10.1093%2Fbioinformatics%2Fbts565)\n\nHectonichus. 2010. Tiphiidae - Tiphia femorata. _Wikipedia_.  https://en.wikipedia.org/wiki/Tiphia_femorata#/media/File:Tiphiidae_-_Tiphia_femorata..jpg. \n\nRautiainen, M., Marschall, T. 2021. MBG: Minimizer-based sparse de Bruijn Graph construction. _Bioinformatics_. 37(16). pp. 2476–2478. DOI: [10.1093/bioinformatics/btab004](https://doi.org/10.1093/bioinformatics/btab004). \n\nWick, RR., Schultz, MB., Zobel, J., Holt, KE. 2015. Bandage: interactive visualization of de novo genome assemblies. _Bioinformatics_. 31(20). pp. 3350–3352. DOI: [10.1093/bioinformatics/btv383](https://doi.org/10.1093/bioinformatics/btv383)","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Work-based-Projects/ONT-Assembly":{"title":"","content":"","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Work-based-Projects/Slack-Bots":{"title":"Slack Bots","content":"\nGitHub:: [BTK-announcer](https://github.com/DLBPointon/btk_announcer), [Weekly-reporter](https://github.com/DLBPointon/weekly-report), [Priority-reporter](https://github.com/DLBPointon/priority_report)\n\nContribution:: Whole Project\n\nWorking with:: JMDW\n\nTopic:: Software Development, CI-CD\n\nKSBs:: B1 \n\n---\nDescription:: Description of the slack bots developed to better inform GRIT and GEVAL-builders\n\n### The Project\nThese three scripts were developed by a need for a simpler method of viewing important data from the sanger JIRA instance. These are automatically run on the internal GitLab repositories (the above github links are mirrors) via a gitlab-ci.yaml and using GitLab Secrets to pass JIRA credentials, see code block 1.\n\n```\nstages:\n - first\n\nvariables:\n    JIRA_PASS: $JIRA_PASS\n    JIRA_USER: $JIRA_USER\n    TEST_HOOK: $SLACK_TEST\n    PROD_HOOK: $SLACK_HOOK\n    JIRA_INST: $JIRA_INST\n    FLAG: $flag\n\nbefore_script:\n    - echo $PATH\n    - apt-get update -qq \u0026\u0026 apt-get install -y python3.9 \u0026\u0026 apt-get install -y python3-pip\n    - python3 -v\n    - pip3 install jira\n    - pip3 install datetime\n    - pip3 install python-dotenv\n    - pip3 install tabulate\n    - pip3 install requests\n    - pip3 install pandas\n\nmrbtk:\n  stage: first\n  tags:\n   - autoscale\n  script:\n    - python3 MrBTK.py $flag\n  retry: 2\n```\nCode Block 1: The .gitlab-ci.yaml file used to run the GitLab pipeline at 9:00am. The variables denoted in the variables block (top to bottom) are: JIRA Password, JIRA Username, Slack webhook for private channel testing, Slack webhook for public channel posting, JIRA instance to scrape data from and a flag to specify whether the script posts to the private or public channel. This structure is used for all three bots. MrBTK is the BTK-anncouncer.\n\n##### MrBTK\nMrBTK is the Slack name for a bot that reads all JIRA tickets that are tagged `BlobToolKit` (BTK). This returns a dictionary with the ticket id of every ticket that has not made it through to the penultimate steps of curation. Subsequent steps then parse whether certain keywords are found in the comments, whether there is a colleuge assigned to the ticket, the workflow the ticket is in  as well as the stage at which the BTK has been assigned. All of these values populate a dictionary which is parsed by the modules `pandas` and `tabulator` to generate a \"pretty\" dataframe that can be sent via the `requests` module to the slack channel, see figure 1. \n\n![[images/mrbtk.png]]\nFigure 1: A MrBTK slack post detailing the tickets that require a BTK being run, those being run and its assignee as well as those that have been completed and are waiting on post-BTK analysis.\n\nBTK is a pipeline used in the identification of potential contamination. Based on the [BlobToolKit2](https://github.com/blobtoolkit/blobtoolkit) pipeline created by Richard Challis, the Sanger based implementation allows for a standarised and quick setup per genomic assembly. This speed is important, especially as DTOL scaled up to dozens of assebmlies per week, it was necessary to see what needed working on at a glance ranther than logging into JIRA and creating a query for this information.\n\n##### Weekly-report\nAlso known as Miss Minutes, as it keeps an eye on the ins and outs of curation, the weekly reporting script was creating after a request by GRIT manager JMDW to enable a form of reporting of the weekly happenings in GRIT.\n\nThis bot generates a rather verbose output, see figure 2, detailing tickets new and old, as well as their status, date of status change, project as well as counts of tickets in the same projects. Due to the size of the output I have not as of yet updated it to use tabulator, shown in figure 1.\n\n![[images/missminutes.png]]\nFigure 2: A Miss Minutes slack post detailing the changes made to tickets over the previous week. Darwin is the main DTOL project, VGP and VGP+ are Vertebrate Genome Projects types and ASG is the Aquatic Symbiosis Genomics project.\n\n##### Priority-report\nPriority-report, also known as Rover, was developed to simply fetch all high-priority tickets due to a number of them \"falling through the net\" and spending a large amount of time waiting to be assigned. \n\nThis results in a large amount of output much like Weekly-report, however due to the lack of segregration by project type it is possible to use `pandas` and `tabulator` to split the output in 15 entry chunks via a small code block that took advantage of splicing, see code block 2.\n\n```\ncounter = 0\nn = 15\n\nfor start in range(0, len(df), n):\n    counter += 1\n    prettier_df = tabulate_df(df[start:start+n])\n    post_it(prettier_df, slack_add, counter)\n```\nCode block 2: A small function which uses splicing to split a large dataframe into 15 entry long segments and post them to slack numbered by the counter variable + 1, to result in **Report 1** rather than **Report 0**. The functions, tabulate_df and post_it, converts the pandas dataframe into a tabulate dataframe and posts the resulting tabulate dataframe to slack respectively.\n\nThis results in output that details the assembly id, ticket id, priority level, status and assignee (if any) attached to the ticket, see figure 3.\n\n![[images/rover.png]]\n![[images/rover2.png]]\nFigure 4: An example of a slack report produced by Rover.\n\n### Future Plans\nFuture plans include updating the weekly-reporting output in a format that is much cleaner such as that generated by BTK-announcer in figure 1. This will require a significant amount of refactoring that will result in at least one slack post per project type, more if there is more than 15 enteries per post due to limitations on the slack webhook API.\n\n\n### Evidence\n\n##### Conversation in setting up priority-report and weekly-report\n\n**JMDW**\nMr_BTK..... can we do one for priority curations?\n\n**DLBP**\nYeah sure, Just in general high priority cases that come in? Where would you like it posted?I'm also most of the way through one for the weekly reporting too, It has everything for what has been updated in the specified week. Also can have everything currently in Open and in Submission, but just by the sheer nature of Jira those can't be filtered by date otherwise you get some anomalies like we've seen before where they will disappear and reappear almost at will.\n\n**JMDW**\nok thanks for manageing to pull everything!regarding the priority.. normal stuff tracks through at medium. would be good to get reports on High and Highest when in the system... track through Open, Decon, build and curation, post process, in submission.\n\nCan you report who assigned to also?\n\n**DLBP**\nNo problem, do you want it sent to a new channel or directly to you?\n\n**JMDW**\ncan probably get pushed to the curation channel.  \nNeed people to see what is needing to be picked up quickly and if things are stuck at stages\n\nCan you send the output here or to me to see before putting it in the channel\n\n**DLBP**\nadded an integration to this channel: Rover\n\nHi Jo, the priority bot is ready to go live now. I can set it to default send a message to you and then you curl a command to get it to run for the curators if thats helpful?\n\n**JMDW**\nok great! thanks\n\n**Rover**\n```\n|-------- Rovers Priority Report for 2021-08-17 --------|  \n|========================================|  \n| RC-68      | Highest | Decontamination | James Torrance |  \n| GRIT-469 | Highest | Decontamination | James Torrance |  \n| GRIT-468 | Highest | Decontamination | James Torrance |  \n| GRIT-464 | High       | Decontamination | James Torrance |  \n| GRIT-463 | High       | Decontamination | James Torrance |  \n| GRIT-447 | High       | Decontamination | James Torrance |  \n| GRIT-446 | High       | Decontamination | James Torrance ||========================================|  \n|--------------- END Report for 2021-08-17 -------------|\n```\n\n**DLBP**\nRover is set to go off at 9 and the curl command to send it off to the curators chat is:  \n\n```\ncurl -X POST \\\n     -F token= {REMOVED} \\\n     -F ref=main \\\n     -F \"variables[TOCURATORS]=CUR\" \\\n\t [https://gitlab.internal.sanger.ac.uk/-{REMOVED}\n```\n\nThe TOCURATORS variable can be set to JMDW, DLBP or CUR if you need it re-running or anything\n\nThere is also a reports channel for the weekly report, it spits out everything in the pipe at the minute + OPEN tickets which are status open and FIN which are submitted.It makes a pretty ugly and lengthy output which is why i've put it in its own channel\n\n**JMDW**\nNice thanks","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Work-based-Projects/TreeVal-md-team-and-tracking-time":{"title":"TreeVal","content":"\nGitHub:: https://github.com/sanger-tol/treeval\n\nContribution:: Nextflow, Python 3.9, Agile\n\nWorking with:: Directly with yy5 and we3, ToL-IT, GRIT and sm15 (ToLa Manager)\n\nTopic:: Collaborative work, Meeting Organisational Goals\n\nKSBs:: S6, S7, B1, B2, B3, B4, B6\n\n---\nDescription:: A Nextflow DSL2 pipeline + Jbrowse Front end to replace gEVAL\n\n### The Project\nBorn out of a need to replace the aging---and no longer fit for purpose---[gEVAL](https://academic.oup.com/gigascience/article/10/1/giaa153/6072294), TreeVal is designed to be a modern replacement in a modern framework. As ToL-IT, at the time of starting TreeVal, was introducing Nextflow as the first standardised workflow language for use in ToL, it was decided that our small working group would follow suite and adopt Nextflows DSL2 language.\n\nWe would also be using a modern framework called JBrowse for displaying the genomic data generated via this pipeline. The benefits of JBrowse include: it being a drop in replacement and improvement of the gEVAL browser, there is an active plugin community and we are able to create plugins for any data required by the curation team.\n\nTreeVal as of 16-12-2022 is in Phase 2. This means we have completed the pipelining of previously non-pipelined softwares (Phase 1) and have also completed a round of bug fixes and high priority changes (Phase 1.5), see figure 1. \n\n![[TreeVal Phase 1.5 (2).png]]\nFigure 1: The Phase 1.5 pipeline diagram for TreeVal\n\n\n#### Multidisciplinary Team\nToL is a very multi-discipliniary team, and the TreeVal team exemplifies this. Whilst all three of us are programmers in the usual assortment of languages (Python 3, JavaScript, R), yy5 specialises in prototyping and algorithms, we3 was previously a web developer and I work on the pipelining logic and tracking, see figure 2. During the time TreeVal has been in developement, and because of this multi-discipliniary background, we have managed to learn a significant amount from each other.\n\n~~#~~#~~#~~#######\nFigure 2: An Iteration of the Kanban Board we use for TreeVal tracking.\n\nThis goes even further when taking into account the wider ToL infrastructure teams which have members which specialise in Piplining with Nextflow (who help with the more niche issues we encounter), others who are Kubernetes experts (who enable the running of the TreeVal instructure) and a team of software developers who we can rely on to make changes where needed and help meet the standards given by ToL-IT and NF-Core.\n\n#### Tracking\nThrough-out the project, we have used Kanban boards to keep track of open tickets and items which require further research. We avoided the use of more heavily strucutred methods such as Agile due to the highly varied time requirements of day-to-day work, this meant that one week could result in no work completed for TreeVal and another could result in multiple sub-worksflows being completed.\n\nThis was started during Phase 1, and due to the number of requests we were receiving about software to test and implement it was decided to create research and development queue an\n\n\n### Future Plans\n\n### Evidence\n","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null},"/Work-based-Projects/Work-based-Project-Homepage":{"title":"","content":"\n## Portfolio Pieces\nTable generated via the Templater and Dataview template: [[templates/workbased_projects]].\n\n| File                                                                                                | Date          | Description                                                                          |\n| --------------------------------------------------------------------------------------------------- | ------------- | ------------------------------------------------------------------------------------ |\n| [[Portfolio Pieces/GRIT-realtime.md\\|GRIT-realtime]]                                                | 50@16-12-2022 | A Full-stack project to generate graphical summaries of post-curation data           |\n| [[Portfolio Pieces/TeloSearch.md\\|TeloSearch]]                                                      | 50@16-12-2022 | A pipeline to find putative telomeric sequence in good quality scaffolded assemblies |\n| [[Portfolio Pieces/Data driven decision making.md\\|Data driven decision making]]                    | 50@16-12-2022 | How data has effected how a project has gone forward.                                |\n| [[Work-based Projects/TreeVal - md team and tracking time.md\\|TreeVal - md team and tracking time]] | 50@16-12-2022 | A Nextflow DSL2 pipeline + Jbrowse Front end to replace gEVAL                        |\n| [[Work-based Projects/Curation of iyTipFemo1.md\\|Curation of iyTipFemo1]]                           | 51@22-12-2022 | How I have curated the reference genome for _Tiphia femorata_.                       |\n\n\n\n\n\n\n## Genome And Assembly Curation\n| Project | Description | Status | Link |\n|---|---|---|---|\n| iyTipFemo1_1 | _Tiphia femorata_ | Done | |\n","lastmodified":"2023-01-06T11:49:26.140213452Z","tags":null}}